{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
    "<center> <h3 style=\"color:green\">In the Name of Allah, the Most Beneficent, the Most Merciful</h3> </center>\n",
    "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTHOR DETAILS and System Details\n",
    "\n",
    "---\n",
    "\n",
    "**Project Title**  \n",
    "*Emotion Prediction System*\n",
    "\n",
    "**Author**  \n",
    "*Muhammad Aliyan Ul Haq Hassani*\n",
    "\n",
    "**Copyright**  \n",
    "&copy; 2024 Muhammad Aliyan\n",
    "\n",
    "**License**  \n",
    "*Public Domain*\n",
    "\n",
    "**Version**  \n",
    "*1.0*\n",
    "\n",
    "**Python Version**\n",
    "*3.12.2*\n",
    "\n",
    "**Ssytem Information**\n",
    "*Windows: Edition\tWindows 10 Pro*\n",
    "*Version\t22H2*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h2 style=\"color:green\">-------------------- PROJECT PURPOSE --------------------</h2> </center>\n",
    "<br>\n",
    "<center><h3>\n",
    "The main purpose of this project is to demonstrate how the Emotion Prediction problem can be treated as a Supervised Machine Learning problem using Python and the Scikit-learn toolkit.\n",
    "</h3></center>\n",
    "<br>\n",
    "<center><h3>For this purpose, In Sha Allah, we will execute the Machine Learning cycle.</h3></center>\n",
    "<br>\n",
    "<center> <h2 style=\"color:green\">-------------------------------------------------------------------------</h2> </center>\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">Emotion Prediction System â€“ Machine Learning Cycle</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Cycle\n",
    "\n",
    "### Four phases of a Machine Learning Cycle are\n",
    "\n",
    "### Training Phase\n",
    "\n",
    "    Build the Model using Training Data\n",
    "\n",
    "### Testing Phase\n",
    "\n",
    "     Evaluate the performance of Model using Testing Data\n",
    "\n",
    "### Application Phase\n",
    "\n",
    "     Deploy the Model in the Real-world, to predict Real-time unseen Data\n",
    "\n",
    "### Feedback Phase\n",
    "\n",
    "    Take Feedback from the Users and Domain Experts to improve the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Sha Allah, we will follow the following steps to execute the Machine Learning Cycle Using a Single File\n",
    "\n",
    "#### Step 1: Import Libraries\n",
    "\n",
    "#### Step 2: Load Sample Data\n",
    "\n",
    "    Step 2.1: View Columns In Dataset\n",
    "    Step 2.2: Keeping Required Columns In Dataset\n",
    "    \n",
    "\n",
    "#### Step 3: Understand and Pre-process Sample Data\n",
    "    \n",
    "    Step 3.1: Download and set stopwords\n",
    "\n",
    "    todo tell about task and also if not remove stop words what will be the effects\n",
    "\n",
    "    run with out cleaning, run with cleaning and dont remove stop words.\n",
    "\n",
    "    Step 3.2: Define a function to clean the text\n",
    "\n",
    "    This function will remove symbols and numbers, convert text to lowercase, and remove stop words.\n",
    "\n",
    "    Step 3.3: Load the data\n",
    "\n",
    "    Step 3.4: Drop rows with NaN values in the text column\n",
    "\n",
    "    Step 3.5: Apply Data Cleaning\n",
    "\n",
    "    Step 3.6: Data After Processing\n",
    "\n",
    "    Step 3.7: Saving Cleaned Data as Seperate CSV File\n",
    "\n",
    "\n",
    "#### Step 4: Splitting Sample Data into Training Data and Testing Data \n",
    "\n",
    "#### Step 5: Label Encoding (Input and Output is converted in Numeric Representation)\n",
    "\n",
    "    Output is already in Numeric so we not need the Label Encoding.  \n",
    "\n",
    "#### Step 6: Execute the Training Phase\n",
    "\n",
    "\n",
    "    Step 6.1: Training Data and Testing Data\n",
    "\n",
    "    Step 6.2: Train the Model\n",
    "\n",
    "    Step 6.3: Save the Trained Model\n",
    "\n",
    "#### Step 7: Execute the Testing Phase \n",
    "\n",
    "    Step 7.1: Load the Saved Model\n",
    "    \n",
    "    Step 7.2: Evluate the Machine Learning Model\n",
    "\n",
    "    Step 7.3: Showing Confusion Matrix\n",
    "\n",
    "\n",
    "#### Step 8: Execute the Application Phase \n",
    "\n",
    "    Step 8.1: Take Input from User, Preprocess it\n",
    "\n",
    "    Step 8.4: Load the Saved Model\n",
    "\n",
    "    Step 8.5: Model Prediction\n",
    "\n",
    "         Step 8.5.1: Apply Model on the Label Encoded Feature Vector of unseen instance and return Prediction to the User\n",
    "\n",
    "#### Step 9: Execute the Feedback Phase \n",
    "\n",
    "#### Step 10: Improve the Model based on Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aliyan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original data can be download from\n",
    "https://www.kaggle.com/datasets/cosmos98/twitter-and-reddit-sentimental-analysis-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Emotion Prediction Data:\n",
      "============\n",
      "\n",
      "Sample data count = 100\n",
      "\n",
      "                                               Tweet Emotion\n",
      "0             False alarm // matoma &amp; Becky hill   anger\n",
      "1  I'm tired of everybody telling me to chill out...   anger\n",
      "2  Im so serious about putting words in my mouth ...   anger\n",
      "3  Can someone make me a priority list of which t...   anger\n",
      "4  @TeaPartyOrg Hes right when the Civil war star...   anger\n",
      "                                                Tweet Emotion\n",
      "95  Riggs dumb ass hell lolol #hilarious #LethalWe...   trust\n",
      "96                        American Schools are lively   trust\n",
      "97  Accept the challenges so that you can feel the...   trust\n",
      "98  Have any of you ever stayed in hostels oversea...   trust\n",
      "99  @ProSyndicate thanks for replying, I'm ironing...   trust\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('emotion_prediction_dataset.csv')\n",
    "\n",
    "print(\"\\n\\nEmotion Prediction Data:\")\n",
    "print(\"============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(f'Sample data count = {len(data)}\\n')\n",
    "print(data.head())\n",
    "print(data.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1: View Columns In Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tweet', 'Emotion'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2: Keeping Required Column In Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Emotion Prediction Data:\n",
      "============\n",
      "\n",
      "  Emotion                                              Tweet\n",
      "0   anger             False alarm // matoma &amp; Becky hill\n",
      "1   anger  I'm tired of everybody telling me to chill out...\n",
      "2   anger  Im so serious about putting words in my mouth ...\n",
      "3   anger  Can someone make me a priority list of which t...\n",
      "4   anger  @TeaPartyOrg Hes right when the Civil war star...\n",
      "   Emotion                                              Tweet\n",
      "95   trust  Riggs dumb ass hell lolol #hilarious #LethalWe...\n",
      "96   trust                        American Schools are lively\n",
      "97   trust  Accept the challenges so that you can feel the...\n",
      "98   trust  Have any of you ever stayed in hostels oversea...\n",
      "99   trust  @ProSyndicate thanks for replying, I'm ironing...\n"
     ]
    }
   ],
   "source": [
    "data = data [['Emotion', 'Tweet']]\n",
    "\n",
    "print(\"\\n\\nEmotion Prediction Data:\")\n",
    "print(\"============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Understand and Pre-process Sample Data\n",
    "\n",
    "## Definition of Pre-processing Sample Data\n",
    "\n",
    "Pre-processing sample data involves cleaning and transforming raw data into a format that can be effectively used for analysis. This step is crucial in natural language processing (NLP) as it helps in improving the performance of machine learning models by removing noise and ensuring consistency.\n",
    "\n",
    "## Impact of Pre-processing Sample Data\n",
    "\n",
    "1. **Improves Data Quality**: Removes irrelevant and redundant information, leading to cleaner and more meaningful data.\n",
    "2. **Enhances Model Accuracy**: By reducing noise and standardizing text, pre-processing helps in achieving better model performance.\n",
    "3. **Facilitates Efficient Data Analysis**: Simplifies the data, making it easier to analyze and interpret.\n",
    "4. **Reduces Complexity**: Helps in reducing the complexity of data by normalizing text and handling missing values.\n",
    "\n",
    "Common pre-processing steps include:\n",
    "- Removing punctuation and special characters\n",
    "- Converting text to lowercase\n",
    "- Removing stopwords\n",
    "- Stemming and lemmatization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Download and set stopwords\n",
    "\n",
    "### Definition of Stopwords\n",
    "\n",
    "Stopwords are commonly used words in a language (such as \"the\", \"is\", \"in\", etc.) that are often filtered out before processing text data. These words are considered to have little value in understanding the content of a document because they are so frequently used.\n",
    "\n",
    "### Impact of Removing Stopwords\n",
    "\n",
    "1. **Reduces Noise**: Eliminates common but unimportant words, helping to focus on the more meaningful words in the text.\n",
    "2. **Improves Model Performance**: Reduces the dimensionality of the data, which can improve the efficiency and accuracy of machine learning models.\n",
    "3. **Enhances Text Analysis**: Helps in highlighting the significant words that contribute to the context and meaning of the text.\n",
    "\n",
    "### Note\n",
    "\n",
    "It is important to understand that removing stopwords is not always necessary and depends on the specific requirements of your text analysis or machine learning task. In some cases, stopwords might carry important contextual information that could be valuable for your analysis. Therefore, it is essential to evaluate whether removing stopwords will benefit or hinder your particular application.\n",
    "\n",
    "### How to Download and Set Stopwords\n",
    "\n",
    "To use stopwords in your text pre-processing steps, you need to download a list of stopwords for the language you are working with. In the case of English, the `nltk` library provides a comprehensive list of stopwords.\n",
    "\n",
    "The following code snippet shows how to download and set stopwords using the `nltk` library:\n",
    "\n",
    "```python\n",
    "# Ensure you have downloaded the stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Set the stopwords for English\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have downloaded the stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Define a function to clean the text\n",
    "\n",
    "This function will remove symbols and numbers, convert text to lowercase, and remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the text\n",
    "def clean_text(text):\n",
    "    # Remove symbols and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stop words\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the sake of clear understanding we will divide clean_text function in seperate function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 1: Remove Symbols and Numbers\n",
    "\n",
    "This function removes all symbols and numbers from the text, leaving only alphabetic characters. This step is important to ensure that the text data is clean and only contains meaningful words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_symbols_numbers(text):\n",
    "    # Remove symbols and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function 2: Convert Text to Lowercase\n",
    "This function converts all characters in the text to lowercase to ensure consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function 3: Remove Stopwords\n",
    "This function removes stopwords from the text, which are common words that may not contribute significant meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Remove stop words\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>False alarm // matoma &amp;amp; Becky hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>I'm tired of everybody telling me to chill out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>Im so serious about putting words in my mouth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>Can someone make me a priority list of which t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>@TeaPartyOrg Hes right when the Civil war star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anger</td>\n",
       "      <td>From harboring Osama bin Laden to its relation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>tomorrow will be the last episode of despair a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>PASTOR - 15 FEET away from shooting victim dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>me: are you guys dating yet #trans #nervous #b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>Collects all the times when Minerva would chew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>10 page script due Friday for class. Who said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>Omg I actually thought she was going to jump. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>You don't know what to expect by Brendon's vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>@LaneWoolery @FFKazman experience all plays a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@Montel_Williams If this ban goes through, it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@PatBlanchfield so you mean â€œlike Uber but for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>disgust</td>\n",
       "      <td>This is awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@thehill George H. Establishment is unhappy Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>disgust</td>\n",
       "      <td>Sky news still pushing the Brexit gloom line, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>disgust</td>\n",
       "      <td>Leave it on there, rule,nimber 1 of carpet cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@vladfucker69 i look rabid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@MichaelSalfino It still destroys Fear The Wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@mcauley_ross rojo is awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@MetPoliceFC is it true none of your players a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>disgust</td>\n",
       "      <td>@stevie7t Why does talksport sound like it's b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fear</td>\n",
       "      <td>In wake of fresh #terror threat and sounding o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fear</td>\n",
       "      <td>@andreasarahco do you actually heely on campus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>fear</td>\n",
       "      <td>@HMiglino @CParks777 @Coco_Wms @bodyfit67 @Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>fear</td>\n",
       "      <td>That old lady is cray cray #scared #BellaIsSoC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fear</td>\n",
       "      <td>hi my names anxiety and i have shaun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fear</td>\n",
       "      <td>Hope I sleep - no nightmare of Bakewell tarts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>fear</td>\n",
       "      <td>@KennyCoble @Rosie these horrific situations w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>fear</td>\n",
       "      <td>@LeafyIsHere will showing off biceps scare you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>fear</td>\n",
       "      <td>courage the cowardly dog is like american horr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>fear</td>\n",
       "      <td>induction day tomorrow for pizza express #nervous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>fear</td>\n",
       "      <td>@SeanUnfiltered Texans are scared of this bunch!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>fear</td>\n",
       "      <td>Now #India is #afraid of #bad .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>fear</td>\n",
       "      <td>if Man U lose i may actually have a nervous br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>joy</td>\n",
       "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>joy</td>\n",
       "      <td>Manchester derby at home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>joy</td>\n",
       "      <td>her; i want a playful relationship\\nme; *kicks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>joy</td>\n",
       "      <td>Happy birthday to Stephen King, a man responsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>joy</td>\n",
       "      <td>Thank you disney themed episode for letting me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>joy</td>\n",
       "      <td>@RadioX @ChrisMoyles wow. not heard this in fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>joy</td>\n",
       "      <td>Happy Birthday, LOST! / #lost #dharmainitiativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>joy</td>\n",
       "      <td>#FF \\n\\n@The_Family_X \\n\\n#soul #blues &amp;amp; #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>joy</td>\n",
       "      <td>@MannersAboveAll *laughs louder this time, sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>joy</td>\n",
       "      <td>@TeamGrout glee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>joy</td>\n",
       "      <td>Mate the thing I get excited about in my profe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>joy</td>\n",
       "      <td>@Mickeyplyler @QualkTalk the refs are in GT's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>joy</td>\n",
       "      <td>@niceoneWern @Alotta_Pain the gleesome threesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>love</td>\n",
       "      <td>All this from a cigarette burning in Laura's h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>love</td>\n",
       "      <td>It's meant to be!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>love</td>\n",
       "      <td>I just got asked to hoco over instagram dm bc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>love</td>\n",
       "      <td>@Bietron ðŸ¤“ dont be sad.. btw good night davina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>love</td>\n",
       "      <td>Focus on yourself. Don't let other's love defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>love</td>\n",
       "      <td>When the sadness leaves you broken in your bed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>love</td>\n",
       "      <td>follow my girl tiff she only got 3 followersðŸ’–ðŸ’˜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>love</td>\n",
       "      <td>Patti seems so sad. She stamped and ran behind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>love</td>\n",
       "      <td>O you who have believed, fear Allah and believ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>optimism</td>\n",
       "      <td>I saved him after ordering him to risk his lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>optimism</td>\n",
       "      <td>May the optimism of tomorrow be your foundatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>optimism</td>\n",
       "      <td>Why is it that we rejoice at a birth and griev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>optimism</td>\n",
       "      <td>Gloriosa Bazigaga on #Rwanda work: 'I lost rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>optimism</td>\n",
       "      <td>The point of living, and being an optimist, is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>optimism</td>\n",
       "      <td>I told my chiropractor 'I'm here for a good ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>optimism</td>\n",
       "      <td>i have so much hair it's a nightmare but it's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>optimism</td>\n",
       "      <td>Carry on my wayward son, there'll be peace whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>pessimism</td>\n",
       "      <td>i was so embarrassed when she saw us i was lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>pessimism</td>\n",
       "      <td>@jeremycorbyn @magstogether my god is @jeremyc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>pessimism</td>\n",
       "      <td>mmmm i'm kinda sad i hope i can shake this bef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pessimism</td>\n",
       "      <td>No one wants to win the wild card because you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>pessimism</td>\n",
       "      <td>@MendipHillsAONB do we think the swallows and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>pessimism</td>\n",
       "      <td>Wishing i was rich so i didnt have to get up t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>pessimism</td>\n",
       "      <td>When will the weeks full of Mondays end?? #dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Itâ€™s possible changing meds is best not done w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>sadness</td>\n",
       "      <td>so gutted i dropped one of my earrings down th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>sadness</td>\n",
       "      <td>@antoboyle I so wish you could someday come to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Summer officially ends today. #sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>sadness</td>\n",
       "      <td>final vestiges of my 90's childhood were just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I was not made for this world. #empath #unhappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>sadness</td>\n",
       "      <td>finally leaving my first job soon. i've been w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>sadness</td>\n",
       "      <td>will brawndo cure my depression? @MikeJudge #I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>sadness</td>\n",
       "      <td>in health we did a think about depression and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Muscled man with huge heart is messing with my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Texans and Astros both shut out tonight. Houst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>surprise</td>\n",
       "      <td>On the last episode of #MakingAMurderer poor B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@thixotropic No. Was so sudden. Hasn't sunk in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>surprise</td>\n",
       "      <td>Ronaldo has been shocking. He's tried to do sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>surprise</td>\n",
       "      <td>I'm so confused by the new American horror sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>surprise</td>\n",
       "      <td>#tulsa - Police manufacture murder... Wonder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>trust</td>\n",
       "      <td>@holly_lolly7 I just have serious respect for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>trust</td>\n",
       "      <td>@WildRoverTours Thank you for follow and its a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>trust</td>\n",
       "      <td>@tabstamlyn @lara_hunt1 I will, next time I'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>trust</td>\n",
       "      <td>@janhopis I found the first few episodes of Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>trust</td>\n",
       "      <td>Riggs dumb ass hell lolol #hilarious #LethalWe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>trust</td>\n",
       "      <td>American Schools are lively</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>trust</td>\n",
       "      <td>Accept the challenges so that you can feel the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>trust</td>\n",
       "      <td>Have any of you ever stayed in hostels oversea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>trust</td>\n",
       "      <td>@ProSyndicate thanks for replying, I'm ironing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Emotion                                              Tweet\n",
       "0          anger             False alarm // matoma &amp; Becky hill\n",
       "1          anger  I'm tired of everybody telling me to chill out...\n",
       "2          anger  Im so serious about putting words in my mouth ...\n",
       "3          anger  Can someone make me a priority list of which t...\n",
       "4          anger  @TeaPartyOrg Hes right when the Civil war star...\n",
       "5          anger  From harboring Osama bin Laden to its relation...\n",
       "6   anticipation  tomorrow will be the last episode of despair a...\n",
       "7   anticipation  PASTOR - 15 FEET away from shooting victim dur...\n",
       "8   anticipation  me: are you guys dating yet #trans #nervous #b...\n",
       "9   anticipation  Collects all the times when Minerva would chew...\n",
       "10  anticipation  10 page script due Friday for class. Who said ...\n",
       "11  anticipation  Omg I actually thought she was going to jump. ...\n",
       "12  anticipation  You don't know what to expect by Brendon's vid...\n",
       "13  anticipation  @LaneWoolery @FFKazman experience all plays a ...\n",
       "14       disgust  @Montel_Williams If this ban goes through, it ...\n",
       "15       disgust  @PatBlanchfield so you mean â€œlike Uber but for...\n",
       "16       disgust                                      This is awful\n",
       "17       disgust  @thehill George H. Establishment is unhappy Tr...\n",
       "18       disgust  Sky news still pushing the Brexit gloom line, ...\n",
       "19       disgust  Leave it on there, rule,nimber 1 of carpet cle...\n",
       "20       disgust                         @vladfucker69 i look rabid\n",
       "21       disgust  @MichaelSalfino It still destroys Fear The Wal...\n",
       "22       disgust                        @mcauley_ross rojo is awful\n",
       "23       disgust  @MetPoliceFC is it true none of your players a...\n",
       "24       disgust  @stevie7t Why does talksport sound like it's b...\n",
       "25          fear  In wake of fresh #terror threat and sounding o...\n",
       "26          fear  @andreasarahco do you actually heely on campus...\n",
       "27          fear  @HMiglino @CParks777 @Coco_Wms @bodyfit67 @Tru...\n",
       "28          fear  That old lady is cray cray #scared #BellaIsSoC...\n",
       "29          fear               hi my names anxiety and i have shaun\n",
       "30          fear  Hope I sleep - no nightmare of Bakewell tarts ...\n",
       "31          fear  @KennyCoble @Rosie these horrific situations w...\n",
       "32          fear    @LeafyIsHere will showing off biceps scare you?\n",
       "33          fear  courage the cowardly dog is like american horr...\n",
       "34          fear  induction day tomorrow for pizza express #nervous\n",
       "35          fear  @SeanUnfiltered Texans are scared of this bunch! \n",
       "36          fear                    Now #India is #afraid of #bad .\n",
       "37          fear  if Man U lose i may actually have a nervous br...\n",
       "38           joy  No but that's so cute. Atsu was probably shy a...\n",
       "39           joy                          Manchester derby at home \n",
       "40           joy  her; i want a playful relationship\\nme; *kicks...\n",
       "41           joy  Happy birthday to Stephen King, a man responsi...\n",
       "42           joy  Thank you disney themed episode for letting me...\n",
       "43           joy  @RadioX @ChrisMoyles wow. not heard this in fo...\n",
       "44           joy  Happy Birthday, LOST! / #lost #dharmainitiativ...\n",
       "45           joy  #FF \\n\\n@The_Family_X \\n\\n#soul #blues &amp; #...\n",
       "46           joy  @MannersAboveAll *laughs louder this time, sha...\n",
       "47           joy                                    @TeamGrout glee\n",
       "48           joy  Mate the thing I get excited about in my profe...\n",
       "49           joy  @Mickeyplyler @QualkTalk the refs are in GT's ...\n",
       "50           joy   @niceoneWern @Alotta_Pain the gleesome threesome\n",
       "51          love  All this from a cigarette burning in Laura's h...\n",
       "52          love                               It's meant to be!!  \n",
       "53          love  I just got asked to hoco over instagram dm bc ...\n",
       "54          love  @Bietron ðŸ¤“ dont be sad.. btw good night davina...\n",
       "55          love  Focus on yourself. Don't let other's love defi...\n",
       "56          love  When the sadness leaves you broken in your bed...\n",
       "57          love  follow my girl tiff she only got 3 followersðŸ’–ðŸ’˜...\n",
       "58          love  Patti seems so sad. She stamped and ran behind...\n",
       "59          love  O you who have believed, fear Allah and believ...\n",
       "60      optimism  I saved him after ordering him to risk his lif...\n",
       "61      optimism  May the optimism of tomorrow be your foundatio...\n",
       "62      optimism  Why is it that we rejoice at a birth and griev...\n",
       "63      optimism  Gloriosa Bazigaga on #Rwanda work: 'I lost rel...\n",
       "64      optimism  The point of living, and being an optimist, is...\n",
       "65      optimism  I told my chiropractor 'I'm here for a good ti...\n",
       "66      optimism  i have so much hair it's a nightmare but it's ...\n",
       "67      optimism  Carry on my wayward son, there'll be peace whe...\n",
       "68     pessimism  i was so embarrassed when she saw us i was lik...\n",
       "69     pessimism  @jeremycorbyn @magstogether my god is @jeremyc...\n",
       "70     pessimism  mmmm i'm kinda sad i hope i can shake this bef...\n",
       "71     pessimism  No one wants to win the wild card because you ...\n",
       "72     pessimism  @MendipHillsAONB do we think the swallows and ...\n",
       "73     pessimism  Wishing i was rich so i didnt have to get up t...\n",
       "74     pessimism  When will the weeks full of Mondays end?? #dis...\n",
       "75       sadness  Itâ€™s possible changing meds is best not done w...\n",
       "76       sadness  so gutted i dropped one of my earrings down th...\n",
       "77       sadness  @antoboyle I so wish you could someday come to...\n",
       "78       sadness             Summer officially ends today. #sadness\n",
       "79       sadness  final vestiges of my 90's childhood were just ...\n",
       "80       sadness    I was not made for this world. #empath #unhappy\n",
       "81       sadness  finally leaving my first job soon. i've been w...\n",
       "82       sadness  will brawndo cure my depression? @MikeJudge #I...\n",
       "83       sadness  in health we did a think about depression and ...\n",
       "84       sadness  Muscled man with huge heart is messing with my...\n",
       "85       sadness  Texans and Astros both shut out tonight. Houst...\n",
       "86      surprise  On the last episode of #MakingAMurderer poor B...\n",
       "87      surprise  @thixotropic No. Was so sudden. Hasn't sunk in...\n",
       "88      surprise  Ronaldo has been shocking. He's tried to do sk...\n",
       "89      surprise  I'm so confused by the new American horror sto...\n",
       "90      surprise  #tulsa - Police manufacture murder... Wonder w...\n",
       "91         trust  @holly_lolly7 I just have serious respect for ...\n",
       "92         trust  @WildRoverTours Thank you for follow and its a...\n",
       "93         trust  @tabstamlyn @lara_hunt1 I will, next time I'll...\n",
       "94         trust  @janhopis I found the first few episodes of Bo...\n",
       "95         trust  Riggs dumb ass hell lolol #hilarious #LethalWe...\n",
       "96         trust                        American Schools are lively\n",
       "97         trust  Accept the challenges so that you can feel the...\n",
       "98         trust  Have any of you ever stayed in hostels oversea...\n",
       "99         trust  @ProSyndicate thanks for replying, I'm ironing..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.4: Drop rows with NaN values in the text column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling NaN Values in the Text Column\n",
    "\n",
    "#### Definition of NaN Values\n",
    "NaN stands for \"Not a Number\" and is used to represent missing or undefined values in a dataset. In the context of text data, NaN values indicate that a particular entry in the text column is missing or empty.\n",
    "\n",
    "#### Purpose of Dropping Rows with NaN Values\n",
    "Dropping rows with NaN values is an essential pre-processing step to ensure that the dataset is clean and complete. Working with incomplete data can lead to errors and unreliable results in text analysis and machine learning models. By removing rows with NaN values, we can:\n",
    "\n",
    "1. **Ensure Data Quality**: Removing incomplete data entries helps maintain the integrity and quality of the dataset.\n",
    "2. **Prevent Errors**: Many text processing functions and machine learning algorithms cannot handle NaN values and will raise errors if they encounter them.\n",
    "3. **Improve Model Performance**: Clean and complete data contributes to more accurate and reliable model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Sample data without Droping Rows with NAN Values\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in the text column\n",
    "data = data.dropna(subset=['Tweet'])\n",
    "data = data.dropna(subset=['Emotion'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Sample data After Droping Rows with NAN Values\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.5: Apply Data Cleaning\n",
    "Remove symbol and numbers \n",
    "Data in original format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                False alarm // matoma &amp; Becky hill\n",
       "1     I'm tired of everybody telling me to chill out...\n",
       "2     Im so serious about putting words in my mouth ...\n",
       "3     Can someone make me a priority list of which t...\n",
       "4     @TeaPartyOrg Hes right when the Civil war star...\n",
       "5     From harboring Osama bin Laden to its relation...\n",
       "6     tomorrow will be the last episode of despair a...\n",
       "7     PASTOR - 15 FEET away from shooting victim dur...\n",
       "8     me: are you guys dating yet #trans #nervous #b...\n",
       "9     Collects all the times when Minerva would chew...\n",
       "10    10 page script due Friday for class. Who said ...\n",
       "11    Omg I actually thought she was going to jump. ...\n",
       "12    You don't know what to expect by Brendon's vid...\n",
       "13    @LaneWoolery @FFKazman experience all plays a ...\n",
       "14    @Montel_Williams If this ban goes through, it ...\n",
       "15    @PatBlanchfield so you mean â€œlike Uber but for...\n",
       "16                                        This is awful\n",
       "17    @thehill George H. Establishment is unhappy Tr...\n",
       "18    Sky news still pushing the Brexit gloom line, ...\n",
       "19    Leave it on there, rule,nimber 1 of carpet cle...\n",
       "20                           @vladfucker69 i look rabid\n",
       "21    @MichaelSalfino It still destroys Fear The Wal...\n",
       "22                          @mcauley_ross rojo is awful\n",
       "23    @MetPoliceFC is it true none of your players a...\n",
       "24    @stevie7t Why does talksport sound like it's b...\n",
       "25    In wake of fresh #terror threat and sounding o...\n",
       "26    @andreasarahco do you actually heely on campus...\n",
       "27    @HMiglino @CParks777 @Coco_Wms @bodyfit67 @Tru...\n",
       "28    That old lady is cray cray #scared #BellaIsSoC...\n",
       "29                 hi my names anxiety and i have shaun\n",
       "30    Hope I sleep - no nightmare of Bakewell tarts ...\n",
       "31    @KennyCoble @Rosie these horrific situations w...\n",
       "32      @LeafyIsHere will showing off biceps scare you?\n",
       "33    courage the cowardly dog is like american horr...\n",
       "34    induction day tomorrow for pizza express #nervous\n",
       "35    @SeanUnfiltered Texans are scared of this bunch! \n",
       "36                      Now #India is #afraid of #bad .\n",
       "37    if Man U lose i may actually have a nervous br...\n",
       "38    No but that's so cute. Atsu was probably shy a...\n",
       "39                            Manchester derby at home \n",
       "40    her; i want a playful relationship\\nme; *kicks...\n",
       "41    Happy birthday to Stephen King, a man responsi...\n",
       "42    Thank you disney themed episode for letting me...\n",
       "43    @RadioX @ChrisMoyles wow. not heard this in fo...\n",
       "44    Happy Birthday, LOST! / #lost #dharmainitiativ...\n",
       "45    #FF \\n\\n@The_Family_X \\n\\n#soul #blues &amp; #...\n",
       "46    @MannersAboveAll *laughs louder this time, sha...\n",
       "47                                      @TeamGrout glee\n",
       "48    Mate the thing I get excited about in my profe...\n",
       "49    @Mickeyplyler @QualkTalk the refs are in GT's ...\n",
       "50     @niceoneWern @Alotta_Pain the gleesome threesome\n",
       "51    All this from a cigarette burning in Laura's h...\n",
       "52                                 It's meant to be!!  \n",
       "53    I just got asked to hoco over instagram dm bc ...\n",
       "54    @Bietron ðŸ¤“ dont be sad.. btw good night davina...\n",
       "55    Focus on yourself. Don't let other's love defi...\n",
       "56    When the sadness leaves you broken in your bed...\n",
       "57    follow my girl tiff she only got 3 followersðŸ’–ðŸ’˜...\n",
       "58    Patti seems so sad. She stamped and ran behind...\n",
       "59    O you who have believed, fear Allah and believ...\n",
       "60    I saved him after ordering him to risk his lif...\n",
       "61    May the optimism of tomorrow be your foundatio...\n",
       "62    Why is it that we rejoice at a birth and griev...\n",
       "63    Gloriosa Bazigaga on #Rwanda work: 'I lost rel...\n",
       "64    The point of living, and being an optimist, is...\n",
       "65    I told my chiropractor 'I'm here for a good ti...\n",
       "66    i have so much hair it's a nightmare but it's ...\n",
       "67    Carry on my wayward son, there'll be peace whe...\n",
       "68    i was so embarrassed when she saw us i was lik...\n",
       "69    @jeremycorbyn @magstogether my god is @jeremyc...\n",
       "70    mmmm i'm kinda sad i hope i can shake this bef...\n",
       "71    No one wants to win the wild card because you ...\n",
       "72    @MendipHillsAONB do we think the swallows and ...\n",
       "73    Wishing i was rich so i didnt have to get up t...\n",
       "74    When will the weeks full of Mondays end?? #dis...\n",
       "75    Itâ€™s possible changing meds is best not done w...\n",
       "76    so gutted i dropped one of my earrings down th...\n",
       "77    @antoboyle I so wish you could someday come to...\n",
       "78               Summer officially ends today. #sadness\n",
       "79    final vestiges of my 90's childhood were just ...\n",
       "80      I was not made for this world. #empath #unhappy\n",
       "81    finally leaving my first job soon. i've been w...\n",
       "82    will brawndo cure my depression? @MikeJudge #I...\n",
       "83    in health we did a think about depression and ...\n",
       "84    Muscled man with huge heart is messing with my...\n",
       "85    Texans and Astros both shut out tonight. Houst...\n",
       "86    On the last episode of #MakingAMurderer poor B...\n",
       "87    @thixotropic No. Was so sudden. Hasn't sunk in...\n",
       "88    Ronaldo has been shocking. He's tried to do sk...\n",
       "89    I'm so confused by the new American horror sto...\n",
       "90    #tulsa - Police manufacture murder... Wonder w...\n",
       "91    @holly_lolly7 I just have serious respect for ...\n",
       "92    @WildRoverTours Thank you for follow and its a...\n",
       "93    @tabstamlyn @lara_hunt1 I will, next time I'll...\n",
       "94    @janhopis I found the first few episodes of Bo...\n",
       "95    Riggs dumb ass hell lolol #hilarious #LethalWe...\n",
       "96                          American Schools are lively\n",
       "97    Accept the challenges so that you can feel the...\n",
       "98    Have any of you ever stayed in hostels oversea...\n",
       "99    @ProSyndicate thanks for replying, I'm ironing...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function to remove symbols and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tweet'] = data['Tweet'].apply(remove_symbols_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See data again to see the implementation of removal of symbols and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    False alarm  matoma amp Becky hill\n",
       "1     Im tired of everybody telling me to chill out ...\n",
       "2     Im so serious about putting words in my mouth ...\n",
       "3     Can someone make me a priority list of which t...\n",
       "4     TeaPartyOrg Hes right when the Civil war start...\n",
       "5     From harboring Osama bin Laden to its relation...\n",
       "6     tomorrow will be the last episode of despair a...\n",
       "7     PASTOR   FEET away from shooting victim during...\n",
       "8     me are you guys dating yet trans nervous blowj...\n",
       "9     Collects all the times when Minerva would chew...\n",
       "10     page script due Friday for class Who said I c...\n",
       "11    Omg I actually thought she was going to jump  ...\n",
       "12    You dont know what to expect by Brendons video...\n",
       "13    LaneWoolery FFKazman experience all plays a ro...\n",
       "14    MontelWilliams If this ban goes through it wil...\n",
       "15    PatBlanchfield so you mean like Uber but for d...\n",
       "16                                        This is awful\n",
       "17    thehill George H Establishment is unhappy Trum...\n",
       "18    Sky news still pushing the Brexit gloom line m...\n",
       "19    Leave it on there rulenimber  of carpet cleani...\n",
       "20                              vladfucker i look rabid\n",
       "21    MichaelSalfino It still destroys Fear The Walk...\n",
       "22                            mcauleyross rojo is awful\n",
       "23    MetPoliceFC is it true none of your players ar...\n",
       "24    steviet Why does talksport sound like its bein...\n",
       "25    In wake of fresh terror threat and sounding of...\n",
       "26    andreasarahco do you actually heely on campus ...\n",
       "27    HMiglino CParks CocoWms bodyfit TruthEqualsFac...\n",
       "28    That old lady is cray cray scared BellaIsSoCut...\n",
       "29                 hi my names anxiety and i have shaun\n",
       "30    Hope I sleep  no nightmare of Bakewell tarts y...\n",
       "31    KennyCoble Rosie these horrific situations wil...\n",
       "32        LeafyIsHere will showing off biceps scare you\n",
       "33    courage the cowardly dog is like american horr...\n",
       "34     induction day tomorrow for pizza express nervous\n",
       "35      SeanUnfiltered Texans are scared of this bunch \n",
       "36                          Now India is afraid of bad \n",
       "37    if Man U lose i may actually have a nervous br...\n",
       "38    No but thats so cute Atsu was probably shy abo...\n",
       "39                            Manchester derby at home \n",
       "40    her i want a playful relationshipnme kicks her...\n",
       "41    Happy birthday to Stephen King a man responsib...\n",
       "42    Thank you disney themed episode for letting me...\n",
       "43    RadioX ChrisMoyles wow not heard this in forev...\n",
       "44    Happy Birthday LOST  lost dharmainitiative yea...\n",
       "45    FF nnTheFamilyX nnsoul blues amp rock bandnnmu...\n",
       "46    MannersAboveAll laughs louder this time shakin...\n",
       "47                                       TeamGrout glee\n",
       "48    Mate the thing I get excited about in my profe...\n",
       "49    Mickeyplyler QualkTalk the refs are in GTs fav...\n",
       "50        niceoneWern AlottaPain the gleesome threesome\n",
       "51    All this from a cigarette burning in Lauras ha...\n",
       "52                                    Its meant to be  \n",
       "53    I just got asked to hoco over instagram dm bc ...\n",
       "54    Bietron  dont be sad btw good night davinago s...\n",
       "55    Focus on yourself Dont let others love define ...\n",
       "56    When the sadness leaves you broken in your bed...\n",
       "57    follow my girl tiff she only got  followers ti...\n",
       "58    Patti seems so sad She stamped and ran behind ...\n",
       "59    O you who have believed fear Allah and believe...\n",
       "60    I saved him after ordering him to risk his lif...\n",
       "61    May the optimism of tomorrow be your foundatio...\n",
       "62    Why is it that we rejoice at a birth and griev...\n",
       "63    Gloriosa Bazigaga on Rwanda work I lost relati...\n",
       "64    The point of living and being an optimist is t...\n",
       "65    I told my chiropractor Im here for a good time...\n",
       "66    i have so much hair its a nightmare but its al...\n",
       "67    Carry on my wayward son therell be peace when ...\n",
       "68    i was so embarrassed when she saw us i was lik...\n",
       "69    jeremycorbyn magstogether my god is jeremycorb...\n",
       "70    mmmm im kinda sad i hope i can shake this befo...\n",
       "71    No one wants to win the wild card because you ...\n",
       "72    MendipHillsAONB do we think the swallows and s...\n",
       "73    Wishing i was rich so i didnt have to get up t...\n",
       "74    When will the weeks full of Mondays end dishea...\n",
       "75    Its possible changing meds is best not done wh...\n",
       "76    so gutted i dropped one of my earrings down th...\n",
       "77    antoboyle I so wish you could someday come to ...\n",
       "78                 Summer officially ends today sadness\n",
       "79    final vestiges of my s childhood were just das...\n",
       "80         I was not made for this world empath unhappy\n",
       "81    finally leaving my first job soon ive been wor...\n",
       "82    will brawndo cure my depression MikeJudge Idio...\n",
       "83    in health we did a think about depression and ...\n",
       "84    Muscled man with huge heart is messing with my...\n",
       "85    Texans and Astros both shut out tonight Housto...\n",
       "86    On the last episode of MakingAMurderer poor Br...\n",
       "87    thixotropic No Was so sudden Hasnt sunk in yet...\n",
       "88    Ronaldo has been shocking Hes tried to do skil...\n",
       "89     Im so confused by the new American horror story \n",
       "90    tulsa  Police manufacture murder Wonder why we...\n",
       "91    hollylolly I just have serious respect for any...\n",
       "92    WildRoverTours Thank you for follow and its a ...\n",
       "93    tabstamlyn larahunt I will next time Ill make ...\n",
       "94    janhopis I found the first few episodes of Boj...\n",
       "95     Riggs dumb ass hell lolol hilarious LethalWeapon\n",
       "96                          American Schools are lively\n",
       "97    Accept the challenges so that you can feel the...\n",
       "98    Have any of you ever stayed in hostels oversea...\n",
       "99    ProSyndicate thanks for replying Im ironing my...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function to convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tweet'] = data['Tweet'].apply(to_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    false alarm  matoma amp becky hill\n",
       "1     im tired of everybody telling me to chill out ...\n",
       "2     im so serious about putting words in my mouth ...\n",
       "3     can someone make me a priority list of which t...\n",
       "4     teapartyorg hes right when the civil war start...\n",
       "5     from harboring osama bin laden to its relation...\n",
       "6     tomorrow will be the last episode of despair a...\n",
       "7     pastor   feet away from shooting victim during...\n",
       "8     me are you guys dating yet trans nervous blowj...\n",
       "9     collects all the times when minerva would chew...\n",
       "10     page script due friday for class who said i c...\n",
       "11    omg i actually thought she was going to jump  ...\n",
       "12    you dont know what to expect by brendons video...\n",
       "13    lanewoolery ffkazman experience all plays a ro...\n",
       "14    montelwilliams if this ban goes through it wil...\n",
       "15    patblanchfield so you mean like uber but for d...\n",
       "16                                        this is awful\n",
       "17    thehill george h establishment is unhappy trum...\n",
       "18    sky news still pushing the brexit gloom line m...\n",
       "19    leave it on there rulenimber  of carpet cleani...\n",
       "20                              vladfucker i look rabid\n",
       "21    michaelsalfino it still destroys fear the walk...\n",
       "22                            mcauleyross rojo is awful\n",
       "23    metpolicefc is it true none of your players ar...\n",
       "24    steviet why does talksport sound like its bein...\n",
       "25    in wake of fresh terror threat and sounding of...\n",
       "26    andreasarahco do you actually heely on campus ...\n",
       "27    hmiglino cparks cocowms bodyfit truthequalsfac...\n",
       "28    that old lady is cray cray scared bellaissocut...\n",
       "29                 hi my names anxiety and i have shaun\n",
       "30    hope i sleep  no nightmare of bakewell tarts y...\n",
       "31    kennycoble rosie these horrific situations wil...\n",
       "32        leafyishere will showing off biceps scare you\n",
       "33    courage the cowardly dog is like american horr...\n",
       "34     induction day tomorrow for pizza express nervous\n",
       "35      seanunfiltered texans are scared of this bunch \n",
       "36                          now india is afraid of bad \n",
       "37    if man u lose i may actually have a nervous br...\n",
       "38    no but thats so cute atsu was probably shy abo...\n",
       "39                            manchester derby at home \n",
       "40    her i want a playful relationshipnme kicks her...\n",
       "41    happy birthday to stephen king a man responsib...\n",
       "42    thank you disney themed episode for letting me...\n",
       "43    radiox chrismoyles wow not heard this in forev...\n",
       "44    happy birthday lost  lost dharmainitiative yea...\n",
       "45    ff nnthefamilyx nnsoul blues amp rock bandnnmu...\n",
       "46    mannersaboveall laughs louder this time shakin...\n",
       "47                                       teamgrout glee\n",
       "48    mate the thing i get excited about in my profe...\n",
       "49    mickeyplyler qualktalk the refs are in gts fav...\n",
       "50        niceonewern alottapain the gleesome threesome\n",
       "51    all this from a cigarette burning in lauras ha...\n",
       "52                                    its meant to be  \n",
       "53    i just got asked to hoco over instagram dm bc ...\n",
       "54    bietron  dont be sad btw good night davinago s...\n",
       "55    focus on yourself dont let others love define ...\n",
       "56    when the sadness leaves you broken in your bed...\n",
       "57    follow my girl tiff she only got  followers ti...\n",
       "58    patti seems so sad she stamped and ran behind ...\n",
       "59    o you who have believed fear allah and believe...\n",
       "60    i saved him after ordering him to risk his lif...\n",
       "61    may the optimism of tomorrow be your foundatio...\n",
       "62    why is it that we rejoice at a birth and griev...\n",
       "63    gloriosa bazigaga on rwanda work i lost relati...\n",
       "64    the point of living and being an optimist is t...\n",
       "65    i told my chiropractor im here for a good time...\n",
       "66    i have so much hair its a nightmare but its al...\n",
       "67    carry on my wayward son therell be peace when ...\n",
       "68    i was so embarrassed when she saw us i was lik...\n",
       "69    jeremycorbyn magstogether my god is jeremycorb...\n",
       "70    mmmm im kinda sad i hope i can shake this befo...\n",
       "71    no one wants to win the wild card because you ...\n",
       "72    mendiphillsaonb do we think the swallows and s...\n",
       "73    wishing i was rich so i didnt have to get up t...\n",
       "74    when will the weeks full of mondays end dishea...\n",
       "75    its possible changing meds is best not done wh...\n",
       "76    so gutted i dropped one of my earrings down th...\n",
       "77    antoboyle i so wish you could someday come to ...\n",
       "78                 summer officially ends today sadness\n",
       "79    final vestiges of my s childhood were just das...\n",
       "80         i was not made for this world empath unhappy\n",
       "81    finally leaving my first job soon ive been wor...\n",
       "82    will brawndo cure my depression mikejudge idio...\n",
       "83    in health we did a think about depression and ...\n",
       "84    muscled man with huge heart is messing with my...\n",
       "85    texans and astros both shut out tonight housto...\n",
       "86    on the last episode of makingamurderer poor br...\n",
       "87    thixotropic no was so sudden hasnt sunk in yet...\n",
       "88    ronaldo has been shocking hes tried to do skil...\n",
       "89     im so confused by the new american horror story \n",
       "90    tulsa  police manufacture murder wonder why we...\n",
       "91    hollylolly i just have serious respect for any...\n",
       "92    wildrovertours thank you for follow and its a ...\n",
       "93    tabstamlyn larahunt i will next time ill make ...\n",
       "94    janhopis i found the first few episodes of boj...\n",
       "95     riggs dumb ass hell lolol hilarious lethalweapon\n",
       "96                          american schools are lively\n",
       "97    accept the challenges so that you can feel the...\n",
       "98    have any of you ever stayed in hostels oversea...\n",
       "99    prosyndicate thanks for replying im ironing my...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function to remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tweet'] = data['Tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     false alarm matoma amp becky hill\n",
       "1     im tired everybody telling chill everythings o...\n",
       "2     im serious putting words mouth bitch dont add ...\n",
       "3     someone make priority list things outraged ord...\n",
       "4     teapartyorg hes right civil war starts wall wa...\n",
       "5     harboring osama bin laden relationship haqqani...\n",
       "6     tomorrow last episode despair arc much shit go...\n",
       "7     pastor feet away shooting victim protest says ...\n",
       "8     guys dating yet trans nervous blowjobs tfb dat...\n",
       "9     collects times minerva would chew cape begins ...\n",
       "10    page script due friday class said could mfa th...\n",
       "11    omg actually thought going jump southpark sout...\n",
       "12    dont know expect brendons video lmao la devote...\n",
       "13    lanewoolery ffkazman experience plays role edu...\n",
       "14    montelwilliams ban goes harm many people disab...\n",
       "15    patblanchfield mean like uber despair someone ...\n",
       "16                                                awful\n",
       "17    thehill george h establishment unhappy trumps ...\n",
       "18    sky news still pushing brexit gloom line manag...\n",
       "19    leave rulenimber carpet cleaning worsethananat...\n",
       "20                                vladfucker look rabid\n",
       "21    michaelsalfino still destroys fear walking dea...\n",
       "22                               mcauleyross rojo awful\n",
       "23    metpolicefc true none players cops drink chill...\n",
       "24    steviet talksport sound like broadcasted someo...\n",
       "25    wake fresh terror threat sounding alert mumbai...\n",
       "26         andreasarahco actually heely campus bc scare\n",
       "27    hmiglino cparks cocowms bodyfit truthequalsfac...\n",
       "28    old lady cray cray scared bellaissocute awe em...\n",
       "29                               hi names anxiety shaun\n",
       "30         hope sleep nightmare bakewell tarts yuk gbbo\n",
       "31    kennycoble rosie horrific situations get worse...\n",
       "32                     leafyishere showing biceps scare\n",
       "33    courage cowardly dog like american horror stor...\n",
       "34         induction day tomorrow pizza express nervous\n",
       "35                   seanunfiltered texans scared bunch\n",
       "36                                     india afraid bad\n",
       "37            man u lose may actually nervous breakdown\n",
       "38    thats cute atsu probably shy photos cherry hel...\n",
       "39                                manchester derby home\n",
       "40             want playful relationshipnme kicks couch\n",
       "41    happy birthday stephen king man responsible be...\n",
       "42    thank disney themed episode letting discover a...\n",
       "43    radiox chrismoyles wow heard forever random gr...\n",
       "44    happy birthday lost lost dharmainitiative year...\n",
       "45    ff nnthefamilyx nnsoul blues amp rock bandnnmu...\n",
       "46    mannersaboveall laughs louder time shaking hea...\n",
       "47                                       teamgrout glee\n",
       "48    mate thing get excited profession mad client s...\n",
       "49        mickeyplyler qualktalk refs gts favor tonight\n",
       "50            niceonewern alottapain gleesome threesome\n",
       "51    cigarette burning lauras hand angle chin purse...\n",
       "52                                                meant\n",
       "53    got asked hoco instagram dm bc someone lost be...\n",
       "54    bietron dont sad btw good night davinago sleep...\n",
       "55    focus dont let others love define youre happy ...\n",
       "56    sadness leaves broken bed hold depths despair ...\n",
       "57              follow girl tiff got followers tiffanyr\n",
       "58    patti seems sad stamped ran behind sofa give p...\n",
       "59    believed fear allah believe messenger give dou...\n",
       "60    saved ordering risk life didnt panic stayed ca...\n",
       "61               may optimism tomorrow foundation today\n",
       "62    rejoice birth grieve funeral person involved m...\n",
       "63    gloriosa bazigaga rwanda work lost relatives g...\n",
       "64    point living optimist foolish enough believe b...\n",
       "65    told chiropractor im good time long time quest...\n",
       "66    much hair nightmare also soft guess winlose si...\n",
       "67    carry wayward son therell peace done lay weary...\n",
       "68    embarrassed saw us like knvfkkjg thinks stalke...\n",
       "69    jeremycorbyn magstogether god jeremycorbyn ful...\n",
       "70                  mmmm im kinda sad hope shake school\n",
       "71       one wants win wild card play cubs road sadness\n",
       "72    mendiphillsaonb think swallows swifts gone pho...\n",
       "73    wishing rich didnt get morning poor sleepy sad...\n",
       "74                  weeks full mondays end disheartened\n",
       "75    possible changing meds best done stress diffic...\n",
       "76              gutted dropped one earrings sink school\n",
       "77    antoboyle wish could someday come spain play c...\n",
       "78                 summer officially ends today sadness\n",
       "79    final vestiges childhood dashed shoals hearing...\n",
       "80                            made world empath unhappy\n",
       "81    finally leaving first job soon ive working sin...\n",
       "82     brawndo cure depression mikejudge idiocracytoday\n",
       "83                    health think depression feel like\n",
       "84    muscled man huge heart messing brain heart los...\n",
       "85    texans astros shut tonight houston back normal...\n",
       "86    last episode makingamurderer poor brendan glad...\n",
       "87    thixotropic sudden hasnt sunk yet leo knew coming\n",
       "88    ronaldo shocking hes tried skill twice hes nea...\n",
       "89                im confused new american horror story\n",
       "90    tulsa police manufacture murder wonder carry b...\n",
       "91    hollylolly serious respect man pull bun better...\n",
       "92    wildrovertours thank follow good website cheer...\n",
       "93    tabstamlyn larahunt next time ill make sure ev...\n",
       "94    janhopis found first episodes bojack incredibl...\n",
       "95     riggs dumb ass hell lolol hilarious lethalweapon\n",
       "96                              american schools lively\n",
       "97          accept challenges feel exhilaration victory\n",
       "98    ever stayed hostels overseas frame reference m...\n",
       "99    prosyndicate thanks replying im ironing shirt ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following function contains the all three tasks for the sake of simplicity we dividied it in three parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the 'tweet' column\n",
    "data['Tweet'] = data['Tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.6: Data After Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Emotion Prediction Data After Preprocessing:\n",
      "=================================================\n",
      "\n",
      "  Emotion                                              Tweet\n",
      "0   anger                  false alarm matoma amp becky hill\n",
      "1   anger  im tired everybody telling chill everythings o...\n",
      "2   anger  im serious putting words mouth bitch dont add ...\n",
      "3   anger  someone make priority list things outraged ord...\n",
      "4   anger  teapartyorg hes right civil war starts wall wa...\n",
      "   Emotion                                              Tweet\n",
      "95   trust   riggs dumb ass hell lolol hilarious lethalweapon\n",
      "96   trust                            american schools lively\n",
      "97   trust        accept challenges feel exhilaration victory\n",
      "98   trust  ever stayed hostels overseas frame reference m...\n",
      "99   trust  prosyndicate thanks replying im ironing shirt ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\\nEmotion Prediction Data After Preprocessing:\")\n",
    "print(\"=================================================\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have to show tweet first and than to show the sentiment type to make things standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Tweet', 'Emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>false alarm matoma amp becky hill</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im tired everybody telling chill everythings o...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im serious putting words mouth bitch dont add ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>someone make priority list things outraged ord...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teapartyorg hes right civil war starts wall wa...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>harboring osama bin laden relationship haqqani...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tomorrow last episode despair arc much shit go...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pastor feet away shooting victim protest says ...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>guys dating yet trans nervous blowjobs tfb dat...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>collects times minerva would chew cape begins ...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>page script due friday class said could mfa th...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>omg actually thought going jump southpark sout...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dont know expect brendons video lmao la devote...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lanewoolery ffkazman experience plays role edu...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>montelwilliams ban goes harm many people disab...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>patblanchfield mean like uber despair someone ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>awful</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>thehill george h establishment unhappy trumps ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sky news still pushing brexit gloom line manag...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>leave rulenimber carpet cleaning worsethananat...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vladfucker look rabid</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>michaelsalfino still destroys fear walking dea...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mcauleyross rojo awful</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>metpolicefc true none players cops drink chill...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>steviet talksport sound like broadcasted someo...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>wake fresh terror threat sounding alert mumbai...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>andreasarahco actually heely campus bc scare</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hmiglino cparks cocowms bodyfit truthequalsfac...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>old lady cray cray scared bellaissocute awe em...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>hi names anxiety shaun</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hope sleep nightmare bakewell tarts yuk gbbo</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kennycoble rosie horrific situations get worse...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>leafyishere showing biceps scare</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>courage cowardly dog like american horror stor...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>induction day tomorrow pizza express nervous</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>seanunfiltered texans scared bunch</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>india afraid bad</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>man u lose may actually nervous breakdown</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>thats cute atsu probably shy photos cherry hel...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>manchester derby home</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>want playful relationshipnme kicks couch</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>happy birthday stephen king man responsible be...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>thank disney themed episode letting discover a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>radiox chrismoyles wow heard forever random gr...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>happy birthday lost lost dharmainitiative year...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ff nnthefamilyx nnsoul blues amp rock bandnnmu...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>mannersaboveall laughs louder time shaking hea...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>teamgrout glee</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mate thing get excited profession mad client s...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>mickeyplyler qualktalk refs gts favor tonight</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>niceonewern alottapain gleesome threesome</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>cigarette burning lauras hand angle chin purse...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>meant</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>got asked hoco instagram dm bc someone lost be...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>bietron dont sad btw good night davinago sleep...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>focus dont let others love define youre happy ...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>sadness leaves broken bed hold depths despair ...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>follow girl tiff got followers tiffanyr</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>patti seems sad stamped ran behind sofa give p...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>believed fear allah believe messenger give dou...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>saved ordering risk life didnt panic stayed ca...</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>may optimism tomorrow foundation today</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>rejoice birth grieve funeral person involved m...</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>gloriosa bazigaga rwanda work lost relatives g...</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>point living optimist foolish enough believe b...</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>told chiropractor im good time long time quest...</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>much hair nightmare also soft guess winlose si...</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>carry wayward son therell peace done lay weary...</td>\n",
       "      <td>optimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>embarrassed saw us like knvfkkjg thinks stalke...</td>\n",
       "      <td>pessimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>jeremycorbyn magstogether god jeremycorbyn ful...</td>\n",
       "      <td>pessimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>mmmm im kinda sad hope shake school</td>\n",
       "      <td>pessimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>one wants win wild card play cubs road sadness</td>\n",
       "      <td>pessimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>mendiphillsaonb think swallows swifts gone pho...</td>\n",
       "      <td>pessimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>wishing rich didnt get morning poor sleepy sad...</td>\n",
       "      <td>pessimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>weeks full mondays end disheartened</td>\n",
       "      <td>pessimism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>possible changing meds best done stress diffic...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>gutted dropped one earrings sink school</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>antoboyle wish could someday come spain play c...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>summer officially ends today sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>final vestiges childhood dashed shoals hearing...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>made world empath unhappy</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>finally leaving first job soon ive working sin...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>brawndo cure depression mikejudge idiocracytoday</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>health think depression feel like</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>muscled man huge heart messing brain heart los...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>texans astros shut tonight houston back normal...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>last episode makingamurderer poor brendan glad...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>thixotropic sudden hasnt sunk yet leo knew coming</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ronaldo shocking hes tried skill twice hes nea...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>im confused new american horror story</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>tulsa police manufacture murder wonder carry b...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>hollylolly serious respect man pull bun better...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>wildrovertours thank follow good website cheer...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>tabstamlyn larahunt next time ill make sure ev...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>janhopis found first episodes bojack incredibl...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>riggs dumb ass hell lolol hilarious lethalweapon</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>american schools lively</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>accept challenges feel exhilaration victory</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ever stayed hostels overseas frame reference m...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>prosyndicate thanks replying im ironing shirt ...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweet       Emotion\n",
       "0                   false alarm matoma amp becky hill         anger\n",
       "1   im tired everybody telling chill everythings o...         anger\n",
       "2   im serious putting words mouth bitch dont add ...         anger\n",
       "3   someone make priority list things outraged ord...         anger\n",
       "4   teapartyorg hes right civil war starts wall wa...         anger\n",
       "5   harboring osama bin laden relationship haqqani...         anger\n",
       "6   tomorrow last episode despair arc much shit go...  anticipation\n",
       "7   pastor feet away shooting victim protest says ...  anticipation\n",
       "8   guys dating yet trans nervous blowjobs tfb dat...  anticipation\n",
       "9   collects times minerva would chew cape begins ...  anticipation\n",
       "10  page script due friday class said could mfa th...  anticipation\n",
       "11  omg actually thought going jump southpark sout...  anticipation\n",
       "12  dont know expect brendons video lmao la devote...  anticipation\n",
       "13  lanewoolery ffkazman experience plays role edu...  anticipation\n",
       "14  montelwilliams ban goes harm many people disab...       disgust\n",
       "15  patblanchfield mean like uber despair someone ...       disgust\n",
       "16                                              awful       disgust\n",
       "17  thehill george h establishment unhappy trumps ...       disgust\n",
       "18  sky news still pushing brexit gloom line manag...       disgust\n",
       "19  leave rulenimber carpet cleaning worsethananat...       disgust\n",
       "20                              vladfucker look rabid       disgust\n",
       "21  michaelsalfino still destroys fear walking dea...       disgust\n",
       "22                             mcauleyross rojo awful       disgust\n",
       "23  metpolicefc true none players cops drink chill...       disgust\n",
       "24  steviet talksport sound like broadcasted someo...       disgust\n",
       "25  wake fresh terror threat sounding alert mumbai...          fear\n",
       "26       andreasarahco actually heely campus bc scare          fear\n",
       "27  hmiglino cparks cocowms bodyfit truthequalsfac...          fear\n",
       "28  old lady cray cray scared bellaissocute awe em...          fear\n",
       "29                             hi names anxiety shaun          fear\n",
       "30       hope sleep nightmare bakewell tarts yuk gbbo          fear\n",
       "31  kennycoble rosie horrific situations get worse...          fear\n",
       "32                   leafyishere showing biceps scare          fear\n",
       "33  courage cowardly dog like american horror stor...          fear\n",
       "34       induction day tomorrow pizza express nervous          fear\n",
       "35                 seanunfiltered texans scared bunch          fear\n",
       "36                                   india afraid bad          fear\n",
       "37          man u lose may actually nervous breakdown          fear\n",
       "38  thats cute atsu probably shy photos cherry hel...           joy\n",
       "39                              manchester derby home           joy\n",
       "40           want playful relationshipnme kicks couch           joy\n",
       "41  happy birthday stephen king man responsible be...           joy\n",
       "42  thank disney themed episode letting discover a...           joy\n",
       "43  radiox chrismoyles wow heard forever random gr...           joy\n",
       "44  happy birthday lost lost dharmainitiative year...           joy\n",
       "45  ff nnthefamilyx nnsoul blues amp rock bandnnmu...           joy\n",
       "46  mannersaboveall laughs louder time shaking hea...           joy\n",
       "47                                     teamgrout glee           joy\n",
       "48  mate thing get excited profession mad client s...           joy\n",
       "49      mickeyplyler qualktalk refs gts favor tonight           joy\n",
       "50          niceonewern alottapain gleesome threesome           joy\n",
       "51  cigarette burning lauras hand angle chin purse...          love\n",
       "52                                              meant          love\n",
       "53  got asked hoco instagram dm bc someone lost be...          love\n",
       "54  bietron dont sad btw good night davinago sleep...          love\n",
       "55  focus dont let others love define youre happy ...          love\n",
       "56  sadness leaves broken bed hold depths despair ...          love\n",
       "57            follow girl tiff got followers tiffanyr          love\n",
       "58  patti seems sad stamped ran behind sofa give p...          love\n",
       "59  believed fear allah believe messenger give dou...          love\n",
       "60  saved ordering risk life didnt panic stayed ca...      optimism\n",
       "61             may optimism tomorrow foundation today      optimism\n",
       "62  rejoice birth grieve funeral person involved m...      optimism\n",
       "63  gloriosa bazigaga rwanda work lost relatives g...      optimism\n",
       "64  point living optimist foolish enough believe b...      optimism\n",
       "65  told chiropractor im good time long time quest...      optimism\n",
       "66  much hair nightmare also soft guess winlose si...      optimism\n",
       "67  carry wayward son therell peace done lay weary...      optimism\n",
       "68  embarrassed saw us like knvfkkjg thinks stalke...     pessimism\n",
       "69  jeremycorbyn magstogether god jeremycorbyn ful...     pessimism\n",
       "70                mmmm im kinda sad hope shake school     pessimism\n",
       "71     one wants win wild card play cubs road sadness     pessimism\n",
       "72  mendiphillsaonb think swallows swifts gone pho...     pessimism\n",
       "73  wishing rich didnt get morning poor sleepy sad...     pessimism\n",
       "74                weeks full mondays end disheartened     pessimism\n",
       "75  possible changing meds best done stress diffic...       sadness\n",
       "76            gutted dropped one earrings sink school       sadness\n",
       "77  antoboyle wish could someday come spain play c...       sadness\n",
       "78               summer officially ends today sadness       sadness\n",
       "79  final vestiges childhood dashed shoals hearing...       sadness\n",
       "80                          made world empath unhappy       sadness\n",
       "81  finally leaving first job soon ive working sin...       sadness\n",
       "82   brawndo cure depression mikejudge idiocracytoday       sadness\n",
       "83                  health think depression feel like       sadness\n",
       "84  muscled man huge heart messing brain heart los...       sadness\n",
       "85  texans astros shut tonight houston back normal...       sadness\n",
       "86  last episode makingamurderer poor brendan glad...      surprise\n",
       "87  thixotropic sudden hasnt sunk yet leo knew coming      surprise\n",
       "88  ronaldo shocking hes tried skill twice hes nea...      surprise\n",
       "89              im confused new american horror story      surprise\n",
       "90  tulsa police manufacture murder wonder carry b...      surprise\n",
       "91  hollylolly serious respect man pull bun better...         trust\n",
       "92  wildrovertours thank follow good website cheer...         trust\n",
       "93  tabstamlyn larahunt next time ill make sure ev...         trust\n",
       "94  janhopis found first episodes bojack incredibl...         trust\n",
       "95   riggs dumb ass hell lolol hilarious lethalweapon         trust\n",
       "96                            american schools lively         trust\n",
       "97        accept challenges feel exhilaration victory         trust\n",
       "98  ever stayed hostels overseas frame reference m...         trust\n",
       "99  prosyndicate thanks replying im ironing shirt ...         trust"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.7: Saving Cleaned Data as Seperate CSV File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"cleaned_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tweet', 'Emotion'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Features and Labels\n",
    "\n",
    "In this step, we separate our data into features (X) and labels (y). The features (X) are the input data that the model will learn from, while the labels (y) are the target values that we want to predict.\n",
    "\n",
    "```python\n",
    "X = data['tweet']\n",
    "y = data['sentiment_type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_tweets.csv')\n",
    "X = data['Tweet']\n",
    "y = data['Emotion']\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['Emotion'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: Feature Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization\n",
    "\n",
    "In this step, we use the `TfidfVectorizer` from the `sklearn.feature_extraction.text` module to convert the text data into numerical features based on the TF-IDF (Term Frequency-Inverse Document Frequency) representation. This helps in capturing the importance of words in the context of the documents they appear in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Vectorizer on the Training Data\n",
    "\n",
    "Before we can transform our text data into TF-IDF features, we need to fit the `TfidfVectorizer` on the training data. This step is crucial as it allows the vectorizer to learn the vocabulary and the importance of each term based on the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_features=10)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=10)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the vectorizer on the training data\n",
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the Training Data\n",
    "\n",
    "After fitting the `TfidfVectorizer` on the training data, the next step is to transform the training text data into a TF-IDF feature matrix. This matrix will be used to train our machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training data\n",
    "X_train_tfidf = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the TF-IDF Sparse Matrix to a DataFrame\n",
    "\n",
    "After transforming the text data into a TF-IDF feature matrix, we convert this sparse matrix into a DataFrame. This makes it easier to inspect and manipulate the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Features DataFrame:\n",
      "   despair      dont  get        im  like  lost  love  man  sad  time\n",
      "0      0.0  0.000000  0.0  0.000000   0.0   0.0   0.0  0.0  0.0   0.0\n",
      "1      0.0  0.000000  0.0  1.000000   0.0   0.0   0.0  0.0  0.0   0.0\n",
      "2      0.0  0.742263  0.0  0.670109   0.0   0.0   0.0  0.0  0.0   0.0\n",
      "3      0.0  0.000000  0.0  0.000000   0.0   0.0   0.0  0.0  0.0   0.0\n",
      "4      0.0  1.000000  0.0  0.000000   0.0   0.0   0.0  0.0  0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the TF-IDF sparse matrix to a DataFrame\n",
    "X_train_tfidf_df = pd.DataFrame(X_train_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "\n",
    "print(\"\\nTF-IDF Features DataFrame:\")\n",
    "print(X_train_tfidf_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 : Label Encoding does not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Execute the Training Phase \n",
    "## Step 6.1: Training Data and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.2: Train the model\n",
    "\n",
    "### Training the Model\n",
    "\n",
    "In this step, we train a machine learning model using the TF-IDF features from the training data.\n",
    "\n",
    "`MultinomialNB()`: This initializes a Multinomial Naive Bayes classifier, which is well-suited for classification with discrete features like word counts or TF-IDF scores.\n",
    "`model.fit(X_train_tfidf, y_train)`: This method trains the Multinomial Naive Bayes model using the TF-IDF features (X_train_tfidf) and the corresponding labels (y_train). The model learns the relationship between the features and the labels, which will later be used to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.3: Save the trained model\n",
    "\n",
    "After training the model, it's important to save both the trained model and the TF-IDF vectorizer to disk. This allows us to reuse them later without retraining, which saves time and computational resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to disk\n",
    "joblib.dump(model, 'naive_bayes_model.pkl')\n",
    "\n",
    "# Save the vectorizer to disk\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Execute the Testing Phase \n",
    "## Step 7.1: Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from 'naive_bayes_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "*------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                      |\n",
    "|               Purpose: Method to Load Previously Saved Model  |\n",
    "|         Arguments:                                            |\n",
    "|               Model: Trained Model                            |\n",
    "|         Return:                                               |\n",
    "|               File: Saved Model will be Loaded in Memory      |\n",
    "*---------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Load the model from disk\n",
    "loaded_model = joblib.load('naive_bayes_model.pkl')\n",
    "\n",
    "# Load the vectorizer from disk\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "print(f\"Model loaded from 'naive_bayes_model.pkl'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.2: Evaluate the Machine Learning Model\n",
    "\n",
    "### Transforming Test Data and Evaluating the Loaded Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00         6\n",
      "anticipation       0.00      0.00      0.00         8\n",
      "     disgust       0.17      0.09      0.12        11\n",
      "        fear       0.14      0.46      0.21        13\n",
      "         joy       0.05      0.15      0.08        13\n",
      "        love       0.00      0.00      0.00         9\n",
      "    optimism       0.00      0.00      0.00         8\n",
      "   pessimism       0.50      0.29      0.36         7\n",
      "     sadness       0.00      0.00      0.00        11\n",
      "    surprise       0.00      0.00      0.00         5\n",
      "       trust       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.11       100\n",
      "   macro avg       0.08      0.09      0.07       100\n",
      "weighted avg       0.08      0.11      0.08       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "y_pred = cross_val_predict(model, X_train_tfidf, y, cv=5)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "report = classification_report(y, y_pred, target_names=label_encoder.classes_)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Execute the Application Phase\n",
    "## Step 8.1: Take Input from User, Preprocess it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take user input\n",
    "user_input = input(\"Please enter your text: \").strip()\n",
    "\n",
    "# Preprocess the user input\n",
    "def preprocess_user_input(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "cleaned_input = preprocess_user_input(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am terrified'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'terrified'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.2: Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vectorizer and the model (ensure these are the same as used during training)\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "model = joblib.load('naive_bayes_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.3: Transform the user input using the loaded vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Features DataFrame for User Input:\n",
      "   despair  dont  get   im  like  lost  love  man  sad  time\n",
      "0      0.0   0.0  0.0  0.0   0.0   0.0   0.0  0.0  0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Transform the cleaned input using the vectorizer\n",
    "X_test_tfidf = vectorizer.transform([cleaned_input])  # Wrap the cleaned input in a list\n",
    "\n",
    "# Convert the TF-IDF sparse matrix to a DataFrame\n",
    "X_test_tfidf_df = pd.DataFrame(X_test_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTF-IDF Features DataFrame for User Input:\")\n",
    "print(X_test_tfidf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the user input using the loaded vectorizer\n",
    "user_input_tfidf = vectorizer.transform([cleaned_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.4: Predict the emotion of the user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Emotion of  'I am terrified'  is: fear\n"
     ]
    }
   ],
   "source": [
    "# Predict the sentiment of the user input\n",
    "user_prediction = model.predict(X_test_tfidf)\n",
    "y_matrix = np.array(y)  \n",
    "y_flattened = y_matrix.flatten()\n",
    "unique_labels = set(y_flattened)\n",
    "unique_original_labels = label_encoder.inverse_transform(list(unique_labels))\n",
    "unique_original_labels.tolist()\n",
    "\n",
    "\n",
    "# Output the prediction\n",
    "print(f\"The Emotion of  '{user_input}'  is: {unique_original_labels[user_prediction[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Execute the Feedback Phase\n",
    "## A Two-Step Process\n",
    "### Step 01: After some time, take Feedback from\n",
    "    o\tDomain Experts and Users on deployed Titanic Passenger Survival Prediction System\n",
    "### Step 02: Make a List of Possible Improvements based on Feedback received"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo gender identificaton form text\n",
    "\n",
    "muti clas age group identification from text, emotion redectipn fronm text. mahy by personalityh type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Improve Model based on Feedback\n",
    "### There is Always Room for Improvement\n",
    "### Based on Feedback from Domain Experts and Users\n",
    "    o\tImprove your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo Task\n",
    "\n",
    "## Choose a dataset from the following links and repeat the processes mentioned in this notebook:\n",
    "The first dataset is compulsory, while the others are provided for additional practice.\n",
    "\n",
    "1. **[Spam Email Dataset](https://www.kaggle.com/datasets/jackksoncsie/spam-email-dataset)** (Compulsory)\n",
    "2. [COVID-19 NLP Text Classification](https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification) (For practice)\n",
    "3. [Fake News Detection](https://www.kaggle.com/datasets/vishakhdapat/fake-news-detection) (For practice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
    "<center> <h3 style=\"color:green\">JAZAK ALLAH KHAIR</h3> \n",
    "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
    "<br><br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
