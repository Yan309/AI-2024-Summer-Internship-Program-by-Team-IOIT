{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
    "<center> <h3 style=\"color:green\">In the Name of Allah, the Most Beneficent, the Most Merciful</h3> </center>\n",
    "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTHOR DETAILS and System Details\n",
    "\n",
    "---\n",
    "\n",
    "**Project Title**  \n",
    "*Gender Prediction System*\n",
    "\n",
    "**Author**  \n",
    "*Muhammad Aliyan Ul Haq Hassani*\n",
    "\n",
    "**Copyright**  \n",
    "&copy; 2024 Muhammad Aliyan\n",
    "\n",
    "**License**  \n",
    "*Public Domain*\n",
    "\n",
    "**Version**  \n",
    "*1.0*\n",
    "\n",
    "**Python Version**\n",
    "*3.12.2*\n",
    "\n",
    "**Ssytem Information**\n",
    "*Windows: Edition\tWindows 10 Pro*\n",
    "*Version\t22H2*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h2 style=\"color:green\">-------------------- PROJECT PURPOSE --------------------</h2> </center>\n",
    "<br>\n",
    "<center><h3>\n",
    "The main purpose of this project is to demonstrate how the Gender Identification problem can be treated as a Supervised Machine Learning problem using Python and the Scikit-learn toolkit.\n",
    "</h3></center>\n",
    "<br>\n",
    "<center><h3>For this purpose, In Sha Allah, we will execute the Machine Learning cycle.</h3></center>\n",
    "<br>\n",
    "<center> <h2 style=\"color:green\">-------------------------------------------------------------------------</h2> </center>\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">Gender Prediction System – Machine Learning Cycle</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Cycle\n",
    "\n",
    "### Four phases of a Machine Learning Cycle are\n",
    "\n",
    "### Training Phase\n",
    "\n",
    "    Build the Model using Training Data\n",
    "\n",
    "### Testing Phase\n",
    "\n",
    "     Evaluate the performance of Model using Testing Data\n",
    "\n",
    "### Application Phase\n",
    "\n",
    "     Deploy the Model in the Real-world, to predict Real-time unseen Data\n",
    "\n",
    "### Feedback Phase\n",
    "\n",
    "    Take Feedback from the Users and Domain Experts to improve the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Sha Allah, we will follow the following steps to execute the Machine Learning Cycle Using a Single File\n",
    "\n",
    "#### Step 1: Import Libraries\n",
    "\n",
    "#### Step 2: Load Sample Data\n",
    "\n",
    "    Step 2.1: View Columns In Dataset\n",
    "    Step 2.2: Keeping Required Columns In Dataset\n",
    "    \n",
    "\n",
    "#### Step 3: Understand and Pre-process Sample Data\n",
    "    \n",
    "    Step 3.1: Download and set stopwords\n",
    "\n",
    "    todo tell about task and also if not remove stop words what will be the effects\n",
    "\n",
    "    run with out cleaning, run with cleaning and dont remove stop words.\n",
    "\n",
    "    Step 3.2: Define a function to clean the text\n",
    "\n",
    "    This function will remove symbols and numbers, convert text to lowercase, and remove stop words.\n",
    "\n",
    "    Step 3.3: Load the data\n",
    "\n",
    "    Step 3.4: Drop rows with NaN values in the text column\n",
    "\n",
    "    Step 3.5: Apply Data Cleaning\n",
    "\n",
    "    Step 3.6: Data After Processing\n",
    "\n",
    "    Step 3.7: Saving Cleaned Data as Seperate CSV File\n",
    "\n",
    "\n",
    "#### Step 4: Splitting Sample Data into Training Data and Testing Data \n",
    "\n",
    "#### Step 5: Label Encoding (Input and Output is converted in Numeric Representation)\n",
    "\n",
    "    Output is already in Numeric so we not need the Label Encoding.  \n",
    "\n",
    "#### Step 6: Execute the Training Phase\n",
    "\n",
    "\n",
    "    Step 6.1: Training Data and Testing Data\n",
    "\n",
    "    Step 6.2: Train the Model\n",
    "\n",
    "    Step 6.3: Save the Trained Model\n",
    "\n",
    "#### Step 7: Execute the Testing Phase \n",
    "\n",
    "    Step 7.1: Load the Saved Model\n",
    "    \n",
    "    Step 7.2: Evluate the Machine Learning Model\n",
    "\n",
    "    Step 7.3: Showing Confusion Matrix\n",
    "\n",
    "\n",
    "#### Step 8: Execute the Application Phase \n",
    "\n",
    "    Step 8.1: Take Input from User, Preprocess it\n",
    "\n",
    "    Step 8.4: Load the Saved Model\n",
    "\n",
    "    Step 8.5: Model Prediction\n",
    "\n",
    "         Step 8.5.1: Apply Model on the Label Encoded Feature Vector of unseen instance and return Prediction to the User\n",
    "\n",
    "#### Step 9: Execute the Feedback Phase \n",
    "\n",
    "#### Step 10: Improve the Model based on Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aliyan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Gender Prediction Data:\n",
      "============\n",
      "\n",
      "Sample data count = 100\n",
      "\n",
      "   gender                                        description\n",
      "0    male                              i sing my own rhythm.\n",
      "1    male  I'm the author of novels filled with family dr...\n",
      "2    male                louis whining and squealing and all\n",
      "3    male  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n",
      "4  female  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...\n",
      "    gender                                        description\n",
      "95   brand                                                NaN\n",
      "96    male                                      Calm And Cool\n",
      "97  female  A retro modernist suffering from unsightly vis...\n",
      "98   brand  Multiple Sclerosis lives here in Brant County ...\n",
      "99    male  Doctorate in Physics, 2 time Olympic swimming ...\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Gender cleaned data.csv', encoding='ISO-8859-1')\n",
    "data = data.head(100)\n",
    "print(\"\\n\\nGender Prediction Data:\")\n",
    "print(\"============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(f'Sample data count = {len(data)}\\n')\n",
    "print(data.head())\n",
    "print(data.tail())\n",
    "# gender\n",
    "# 1 is Female\n",
    "# 0 is Male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1: View Columns In Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'description'], dtype='object')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2: Keeping Required Column In Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Gender Prediction Data:\n",
      "============\n",
      "\n",
      "   gender                                        description\n",
      "0    male                              i sing my own rhythm.\n",
      "1    male  I'm the author of novels filled with family dr...\n",
      "2    male                louis whining and squealing and all\n",
      "3    male  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n",
      "4  female  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...\n",
      "    gender                                        description\n",
      "95   brand                                                NaN\n",
      "96    male                                      Calm And Cool\n",
      "97  female  A retro modernist suffering from unsightly vis...\n",
      "98   brand  Multiple Sclerosis lives here in Brant County ...\n",
      "99    male  Doctorate in Physics, 2 time Olympic swimming ...\n"
     ]
    }
   ],
   "source": [
    "data = data [['gender', 'description']]\n",
    "\n",
    "print(\"\\n\\nGender Prediction Data:\")\n",
    "print(\"============\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Understand and Pre-process Sample Data\n",
    "\n",
    "## Definition of Pre-processing Sample Data\n",
    "\n",
    "Pre-processing sample data involves cleaning and transforming raw data into a format that can be effectively used for analysis. This step is crucial in natural language processing (NLP) as it helps in improving the performance of machine learning models by removing noise and ensuring consistency.\n",
    "\n",
    "## Impact of Pre-processing Sample Data\n",
    "\n",
    "1. **Improves Data Quality**: Removes irrelevant and redundant information, leading to cleaner and more meaningful data.\n",
    "2. **Enhances Model Accuracy**: By reducing noise and standardizing text, pre-processing helps in achieving better model performance.\n",
    "3. **Facilitates Efficient Data Analysis**: Simplifies the data, making it easier to analyze and interpret.\n",
    "4. **Reduces Complexity**: Helps in reducing the complexity of data by normalizing text and handling missing values.\n",
    "\n",
    "Common pre-processing steps include:\n",
    "- Removing punctuation and special characters\n",
    "- Converting text to lowercase\n",
    "- Removing stopwords\n",
    "- Stemming and lemmatization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Download and set stopwords\n",
    "\n",
    "### Definition of Stopwords\n",
    "\n",
    "Stopwords are commonly used words in a language (such as \"the\", \"is\", \"in\", etc.) that are often filtered out before processing text data. These words are considered to have little value in understanding the content of a document because they are so frequently used.\n",
    "\n",
    "### Impact of Removing Stopwords\n",
    "\n",
    "1. **Reduces Noise**: Eliminates common but unimportant words, helping to focus on the more meaningful words in the text.\n",
    "2. **Improves Model Performance**: Reduces the dimensionality of the data, which can improve the efficiency and accuracy of machine learning models.\n",
    "3. **Enhances Text Analysis**: Helps in highlighting the significant words that contribute to the context and meaning of the text.\n",
    "\n",
    "### Note\n",
    "\n",
    "It is important to understand that removing stopwords is not always necessary and depends on the specific requirements of your text analysis or machine learning task. In some cases, stopwords might carry important contextual information that could be valuable for your analysis. Therefore, it is essential to evaluate whether removing stopwords will benefit or hinder your particular application.\n",
    "\n",
    "### How to Download and Set Stopwords\n",
    "\n",
    "To use stopwords in your text pre-processing steps, you need to download a list of stopwords for the language you are working with. In the case of English, the `nltk` library provides a comprehensive list of stopwords.\n",
    "\n",
    "The following code snippet shows how to download and set stopwords using the `nltk` library:\n",
    "\n",
    "```python\n",
    "# Ensure you have downloaded the stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Set the stopwords for English\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have downloaded the stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Define a function to clean the text\n",
    "\n",
    "This function will remove symbols and numbers, convert text to lowercase, and remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the text\n",
    "def clean_text(text):\n",
    "    # Remove symbols and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stop words\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the sake of clear understanding we will divide clean_text function in seperate function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 1: Remove Symbols and Numbers\n",
    "\n",
    "This function removes all symbols and numbers from the text, leaving only alphabetic characters. This step is important to ensure that the text data is clean and only contains meaningful words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_symbols_numbers(text):\n",
    "    # Remove symbols and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function 2: Convert Text to Lowercase\n",
    "This function converts all characters in the text to lowercase to ensure consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function 3: Remove Stopwords\n",
    "This function removes stopwords from the text, which are common words that may not contribute significant meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Remove stop words\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.3: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     gender                                        description\n",
      "0      male                              i sing my own rhythm.\n",
      "1      male  I'm the author of novels filled with family dr...\n",
      "2      male                louis whining and squealing and all\n",
      "3      male  Mobile guy.  49ers, Shazam, Google, Kleiner Pe...\n",
      "4    female  Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...\n",
      "5    female                                 you don't know me.\n",
      "6     brand  A global marketplace for images, videos and mu...\n",
      "7      male    The secret of getting ahead is getting started.\n",
      "8    female         Pll Fan // Crazy about MCD // Ramen is bae\n",
      "9    female  Renaissance art historian, University of Notti...\n",
      "10    brand  Clean food that tastes great while providing e...\n",
      "11    brand                      highly extraordinary auctions\n",
      "12   female                         Senior '16 . XI-XII-MMXIV.\n",
      "13    brand  Come join the fastest blog network online toda...\n",
      "14   female  im just here for tÌüp, bo burnham, and disney ...\n",
      "15   female                                                NaN\n",
      "16   female                                         JMKM_Òü\n",
      "17     male  Over enthusiastic F1 fan.  Model collector, mu...\n",
      "18     male                                                NaN\n",
      "19  unknown                                                NaN\n",
      "20   female  Artisan specializing in paper mache, print-mak...\n",
      "21   female          He bled and died to take away my sins ÛÊ\n",
      "22   female                                       union j xxxx\n",
      "23     male                          You had me from the start\n",
      "24     male                      BSc economics graduate  #COYS\n",
      "25   female  Wife to my Coach. Mom to my eight troops. Foll...\n",
      "26    brand  If you have any questions about Islam and woul...\n",
      "27    brand  14 ,Canadian , Space enthusiast , future astro...\n",
      "28   female                My Dms closed. | Sc: Dear_Moonshine\n",
      "29     male  RL/writer | Lewd aspiring femboy who enjoys on...\n",
      "30    brand  Breaking industry news for people who believe ...\n",
      "31     male  Award Winning Author of the paranormal Romance...\n",
      "32   female  self-proclaimed princess and occasional pain i...\n",
      "33     male  K-Smooty~I drink alot. Could be worse. I'm scr...\n",
      "34    brand  Everything you need to find a job and keep it!...\n",
      "35     male  Free Ma Bros #EBK #OTR #Real300 !\\n\\nAll I Kno...\n",
      "36    brand  Our nationÛªs leading voice for #ChildCare. A...\n",
      "37   female                       penn state alum #classof2015\n",
      "38    brand  mirage homage...\\ncapri eternal...\\nhopeless r...\n",
      "39     male  Lover of Women, Dogs/cats (dogs), Movies, Comi...\n",
      "40    brand  A collective of genre specific blogs combining...\n",
      "41     male  Militante y obrero de los SueÌ±os Revolucionar...\n",
      "42    brand  Love Animals? FetchFind is the new way to find...\n",
      "43     male            Baby I'm perfect for you @NiallOfficial\n",
      "44     male  Kennedy J Abulala ni mwalimu anayeienzi kazi y...\n",
      "45     male       [ Krothedj@gmail.com ] [ Instagram - DJKRO ]\n",
      "46   female   Slightly ginger with blue eyes.\\nPark Run _ü\n",
      "47     male      Just Living Life at the top of the food chain\n",
      "48   female                               19 | NSS | IPGKK ÏÎ\n",
      "49    brand                                                NaN\n",
      "50     male  Home Office & Business are sweet business! I c...\n",
      "51   female  GoodMorning Mentions Anyone !! \\n\\n #RETWEEET ...\n",
      "52    brand  #Pc #xbox #playstation #eSports #Music #EDM #S...\n",
      "53     male  warholian obsessor creating within an orwellia...\n",
      "54     male                                                NaN\n",
      "55     male               The Blades. Instagram - scottryan16.\n",
      "56   female  This is control. \\nJpn versionàÕ @Zoe_o_Jbot ...\n",
      "57    brand  You Can have What You Want in LifeÛ_. Adverti...\n",
      "58     male                                Just a curious guy.\n",
      "59    brand       Discover how to heal your illness and pains!\n",
      "60    brand  Team di reporter e giornalisti, lavoriamo con ...\n",
      "61   female                                    I like to sleep\n",
      "62   female  ask no questions and you'll get no lies @spoop...\n",
      "63     male  For any photography bookings or enquiries DM, ...\n",
      "64   female  Born in Czech Republic, live in Ireland, wanna...\n",
      "65     male  ' You are to me All that an angel could be. ' ...\n",
      "66     male  Following the Money, Opening Governance, Fight...\n",
      "67   female           Retired Bad Girl. \\nÛ¢Û¢ QUEEN! Û¢Û¢\n",
      "68   female                        walk by faith not by sight.\n",
      "69   female  H50 NCISLA Bones Castle Arrow Chicago Fire Chi...\n",
      "70     male  Apollo bot pulling from both AJ and DD. Random...\n",
      "71    brand  South Beach 229 9th Street Miami Beach, FL 331...\n",
      "72     male                                           ÷üå©\n",
      "73     male  like the snow, beautiful! but coldãü. I'm ...\n",
      "74    brand  Official Twitter Account of the Wichita Falls ...\n",
      "75   female  Wife of Tidy Boy Amadeus, director of The Idea...\n",
      "76    brand  Delivering you up-to-date news from the entert...\n",
      "77   female  A lie gets halfway around the world before the...\n",
      "78     male            Lover of the truth, seeker of knowledge\n",
      "79     male  Why Chase Trends When You Can Make A Statement...\n",
      "80   female              Calm and Collected. #FollowBackAndSee\n",
      "81   female  Artist  Õ Re-evaluating life ÕRadiation Onco...\n",
      "82    brand  TCG is a staffing firm that places design, int...\n",
      "83   female  hi. my name is Angela but most of my friends c...\n",
      "84    brand  Sports, media, opinion. Established 2006. Cont...\n",
      "85     male  I repair all makes and models of phones, table...\n",
      "86     male  Sportswriter, cigar lover, dreamer. Pro writer...\n",
      "87   female                                  Charity volunteer\n",
      "88    brand  Hip Hop USB Albums / BreakStix / USB Break Bea...\n",
      "89    brand  ÷É 150312 ÷É 150314 ÷É 150315 ÷É 150515 ÷...\n",
      "90   female                                                NaN\n",
      "91    brand  The card that get you everywhere, anything, an...\n",
      "92  unknown                            Boring, boring Chelsea.\n",
      "93    brand  All the #Dallas #TX news you need in one spot....\n",
      "94     male  Maker, Conceptor & Creative Developer - 0xBAC3...\n",
      "95    brand                                                NaN\n",
      "96     male                                      Calm And Cool\n",
      "97   female  A retro modernist suffering from unsightly vis...\n",
      "98    brand  Multiple Sclerosis lives here in Brant County ...\n",
      "99     male  Doctorate in Physics, 2 time Olympic swimming ...\n"
     ]
    }
   ],
   "source": [
    "# Load the data (already loaded)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.4: Drop rows with NaN values in the text column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling NaN Values in the Text Column\n",
    "\n",
    "#### Definition of NaN Values\n",
    "NaN stands for \"Not a Number\" and is used to represent missing or undefined values in a dataset. In the context of text data, NaN values indicate that a particular entry in the text column is missing or empty.\n",
    "\n",
    "#### Purpose of Dropping Rows with NaN Values\n",
    "Dropping rows with NaN values is an essential pre-processing step to ensure that the dataset is clean and complete. Working with incomplete data can lead to errors and unreliable results in text analysis and machine learning models. By removing rows with NaN values, we can:\n",
    "\n",
    "1. **Ensure Data Quality**: Removing incomplete data entries helps maintain the integrity and quality of the dataset.\n",
    "2. **Prevent Errors**: Many text processing functions and machine learning algorithms cannot handle NaN values and will raise errors if they encounter them.\n",
    "3. **Improve Model Performance**: Clean and complete data contributes to more accurate and reliable model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Sample data without Droping Rows with NAN Values\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in the text column\n",
    "data = data.dropna(subset=['description'])\n",
    "data = data.dropna(subset=['gender'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "     gender                                        description\n",
      "0      male                                        sing rhythm\n",
      "1      male       im author novels filled family drama romance\n",
      "2      male                            louis whining squealing\n",
      "3      male  mobile guy ers shazam google kleiner perkins y...\n",
      "4    female  ricky wilson best frontmankaiser chiefs best b...\n",
      "5    female                                          dont know\n",
      "6     brand  global marketplace images videos music sharing...\n",
      "7      male               secret getting ahead getting started\n",
      "8    female                        pll fan crazy mcd ramen bae\n",
      "9    female  renaissance art historian university nottingha...\n",
      "10    brand  clean food tastes great providing energy nutri...\n",
      "11    brand                      highly extraordinary auctions\n",
      "12   female                                  senior xixiimmxiv\n",
      "13    brand  come join fastest blog network online today ht...\n",
      "14   female                      im tp bo burnham disney world\n",
      "15   female                                               jmkm\n",
      "16     male  enthusiastic f fan model collector music fan f...\n",
      "17   female  artisan specializing paper mache printmaking f...\n",
      "18   female                           bled died take away sins\n",
      "19   female                                       union j xxxx\n",
      "20     male                                              start\n",
      "21     male                        bsc economics graduate coys\n",
      "22   female        wife coach mom eight troops follower christ\n",
      "23    brand  questions islam would like answer visit httptc...\n",
      "24    brand  canadian space enthusiast future astronaut hop...\n",
      "25   female                        dms closed sc dearmoonshine\n",
      "26     male  rlwriter lewd aspiring femboy enjoys oneechans...\n",
      "27    brand  breaking industry news people believe theres t...\n",
      "28     male  award winning author paranormal romance thrill...\n",
      "29   female        selfproclaimed princess occasional pain ass\n",
      "30     male  ksmootyi drink alot could worse im scrolling g...\n",
      "31    brand  everything need find job keep follow tweet new...\n",
      "32     male          free bros ebk otr real kno grind wea come\n",
      "33    brand  nations leading voice childcare advocating aff...\n",
      "34   female                            penn state alum classof\n",
      "35    brand  mirage homage capri eternal hopeless romantic ...\n",
      "36     male  lover women dogscats dogs movies comics tv vid...\n",
      "37    brand  collective genre specific blogs combining like...\n",
      "38     male  militante obrero de los sueos revolucionarios ...\n",
      "39    brand  love animals fetchfind new way find jobs netwo...\n",
      "40     male                      baby im perfect niallofficial\n",
      "41     male  kennedy j abulala ni mwalimu anayeienzi kazi y...\n",
      "42     male                   krothedjgmailcom instagram djkro\n",
      "43   female                 slightly ginger blue eyes park run\n",
      "44     male                         living life top food chain\n",
      "45   female                                          nss ipgkk\n",
      "46     male                home office business sweet business\n",
      "47   female  goodmorning mentions anyone retweeet must foll...\n",
      "48    brand   pc xbox playstation esports music edm stocks sex\n",
      "49     male  warholian obsessor creating within orwellian n...\n",
      "50     male                         blades instagram scottryan\n",
      "51   female       control jpn version zoeojbot rayarkimplosion\n",
      "52    brand  want life advertise service free get rid money...\n",
      "53     male                                        curious guy\n",
      "54    brand                        discover heal illness pains\n",
      "55    brand  team di reporter e giornalisti lavoriamo con v...\n",
      "56   female                                         like sleep\n",
      "57   female          ask questions youll get lies spoopytaylor\n",
      "58     male  photography bookings enquiries dm call email a...\n",
      "59   female  born czech republic live ireland wanna germany...\n",
      "60     male                                        angel could\n",
      "61     male  following money opening governance fighting co...\n",
      "62   female                             retired bad girl queen\n",
      "63   female                                   walk faith sight\n",
      "64   female  h ncisla bones castle arrow chicago fire chica...\n",
      "65     male  apollo bot pulling aj dd randomly posts every ...\n",
      "66    brand  south beach th street miami beach fl sunny isl...\n",
      "68     male  like snow beautiful cold im legal drug dealer ...\n",
      "69    brand  official twitter account wichita falls wildcat...\n",
      "70   female  wife tidy boy amadeus director ideal place pro...\n",
      "71    brand       delivering uptodate news entertainment world\n",
      "72   female  lie gets halfway around world truth chance get...\n",
      "73     male                       lover truth seeker knowledge\n",
      "74     male  chase trends make statement hoodlyfe httpstcoa...\n",
      "75   female                    calm collected followbackandsee\n",
      "76   female  artist reevaluating life radiation oncology st...\n",
      "77    brand  tcg staffing firm places design interactive ma...\n",
      "78   female  hi name angela friends call angie boring life ...\n",
      "79    brand  sports media opinion established contact us jm...\n",
      "80     male  repair makes models phones tablets mp players ...\n",
      "81     male  sportswriter cigar lover dreamer pro writer sp...\n",
      "82   female                                  charity volunteer\n",
      "83    brand  hip hop usb albums breakstix usb break beats h...\n",
      "85    brand  card get everywhere anything anyhow please use...\n",
      "86  unknown                              boring boring chelsea\n",
      "87    brand  dallas tx news need one spot thanks following ...\n",
      "88     male  maker conceptor creative developer xbacabd con...\n",
      "89     male                                          calm cool\n",
      "90   female     retro modernist suffering unsightly visibility\n",
      "91    brand  multiple sclerosis lives brant county together...\n",
      "92     male  doctorate physics time olympic swimming gold m...\n"
     ]
    }
   ],
   "source": [
    "# Sample data After Droping Rows with NAN Values\n",
    "print(len(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.5: Apply Data Cleaning\n",
    "Remove symbol and numbers \n",
    "Data in original format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           sing rhythm\n",
       "1          im author novels filled family drama romance\n",
       "2                               louis whining squealing\n",
       "3     mobile guy ers shazam google kleiner perkins y...\n",
       "4     ricky wilson best frontmankaiser chiefs best b...\n",
       "5                                             dont know\n",
       "6     global marketplace images videos music sharing...\n",
       "7                  secret getting ahead getting started\n",
       "8                           pll fan crazy mcd ramen bae\n",
       "9     renaissance art historian university nottingha...\n",
       "10    clean food tastes great providing energy nutri...\n",
       "11                        highly extraordinary auctions\n",
       "12                                    senior xixiimmxiv\n",
       "13    come join fastest blog network online today ht...\n",
       "14                        im tp bo burnham disney world\n",
       "15                                                 jmkm\n",
       "16    enthusiastic f fan model collector music fan f...\n",
       "17    artisan specializing paper mache printmaking f...\n",
       "18                             bled died take away sins\n",
       "19                                         union j xxxx\n",
       "20                                                start\n",
       "21                          bsc economics graduate coys\n",
       "22          wife coach mom eight troops follower christ\n",
       "23    questions islam would like answer visit httptc...\n",
       "24    canadian space enthusiast future astronaut hop...\n",
       "25                          dms closed sc dearmoonshine\n",
       "26    rlwriter lewd aspiring femboy enjoys oneechans...\n",
       "27    breaking industry news people believe theres t...\n",
       "28    award winning author paranormal romance thrill...\n",
       "29          selfproclaimed princess occasional pain ass\n",
       "30    ksmootyi drink alot could worse im scrolling g...\n",
       "31    everything need find job keep follow tweet new...\n",
       "32            free bros ebk otr real kno grind wea come\n",
       "33    nations leading voice childcare advocating aff...\n",
       "34                              penn state alum classof\n",
       "35    mirage homage capri eternal hopeless romantic ...\n",
       "36    lover women dogscats dogs movies comics tv vid...\n",
       "37    collective genre specific blogs combining like...\n",
       "38    militante obrero de los sueos revolucionarios ...\n",
       "39    love animals fetchfind new way find jobs netwo...\n",
       "40                        baby im perfect niallofficial\n",
       "41    kennedy j abulala ni mwalimu anayeienzi kazi y...\n",
       "42                     krothedjgmailcom instagram djkro\n",
       "43                   slightly ginger blue eyes park run\n",
       "44                           living life top food chain\n",
       "45                                            nss ipgkk\n",
       "46                  home office business sweet business\n",
       "47    goodmorning mentions anyone retweeet must foll...\n",
       "48     pc xbox playstation esports music edm stocks sex\n",
       "49    warholian obsessor creating within orwellian n...\n",
       "50                           blades instagram scottryan\n",
       "51         control jpn version zoeojbot rayarkimplosion\n",
       "52    want life advertise service free get rid money...\n",
       "53                                          curious guy\n",
       "54                          discover heal illness pains\n",
       "55    team di reporter e giornalisti lavoriamo con v...\n",
       "56                                           like sleep\n",
       "57            ask questions youll get lies spoopytaylor\n",
       "58    photography bookings enquiries dm call email a...\n",
       "59    born czech republic live ireland wanna germany...\n",
       "60                                          angel could\n",
       "61    following money opening governance fighting co...\n",
       "62                               retired bad girl queen\n",
       "63                                     walk faith sight\n",
       "64    h ncisla bones castle arrow chicago fire chica...\n",
       "65    apollo bot pulling aj dd randomly posts every ...\n",
       "66    south beach th street miami beach fl sunny isl...\n",
       "68    like snow beautiful cold im legal drug dealer ...\n",
       "69    official twitter account wichita falls wildcat...\n",
       "70    wife tidy boy amadeus director ideal place pro...\n",
       "71         delivering uptodate news entertainment world\n",
       "72    lie gets halfway around world truth chance get...\n",
       "73                         lover truth seeker knowledge\n",
       "74    chase trends make statement hoodlyfe httpstcoa...\n",
       "75                      calm collected followbackandsee\n",
       "76    artist reevaluating life radiation oncology st...\n",
       "77    tcg staffing firm places design interactive ma...\n",
       "78    hi name angela friends call angie boring life ...\n",
       "79    sports media opinion established contact us jm...\n",
       "80    repair makes models phones tablets mp players ...\n",
       "81    sportswriter cigar lover dreamer pro writer sp...\n",
       "82                                    charity volunteer\n",
       "83    hip hop usb albums breakstix usb break beats h...\n",
       "85    card get everywhere anything anyhow please use...\n",
       "86                                boring boring chelsea\n",
       "87    dallas tx news need one spot thanks following ...\n",
       "88    maker conceptor creative developer xbacabd con...\n",
       "89                                            calm cool\n",
       "90       retro modernist suffering unsightly visibility\n",
       "91    multiple sclerosis lives brant county together...\n",
       "92    doctorate physics time olympic swimming gold m...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function to remove symbols and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description'] = data['description'].apply(remove_symbols_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See data again to see the implementation of removal of symbols and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           sing rhythm\n",
       "1          im author novels filled family drama romance\n",
       "2                               louis whining squealing\n",
       "3     mobile guy ers shazam google kleiner perkins y...\n",
       "4     ricky wilson best frontmankaiser chiefs best b...\n",
       "5                                             dont know\n",
       "6     global marketplace images videos music sharing...\n",
       "7                  secret getting ahead getting started\n",
       "8                           pll fan crazy mcd ramen bae\n",
       "9     renaissance art historian university nottingha...\n",
       "10    clean food tastes great providing energy nutri...\n",
       "11                        highly extraordinary auctions\n",
       "12                                    senior xixiimmxiv\n",
       "13    come join fastest blog network online today ht...\n",
       "14                        im tp bo burnham disney world\n",
       "15                                                 jmkm\n",
       "16    enthusiastic f fan model collector music fan f...\n",
       "17    artisan specializing paper mache printmaking f...\n",
       "18                             bled died take away sins\n",
       "19                                         union j xxxx\n",
       "20                                                start\n",
       "21                          bsc economics graduate coys\n",
       "22          wife coach mom eight troops follower christ\n",
       "23    questions islam would like answer visit httptc...\n",
       "24    canadian space enthusiast future astronaut hop...\n",
       "25                          dms closed sc dearmoonshine\n",
       "26    rlwriter lewd aspiring femboy enjoys oneechans...\n",
       "27    breaking industry news people believe theres t...\n",
       "28    award winning author paranormal romance thrill...\n",
       "29          selfproclaimed princess occasional pain ass\n",
       "30    ksmootyi drink alot could worse im scrolling g...\n",
       "31    everything need find job keep follow tweet new...\n",
       "32            free bros ebk otr real kno grind wea come\n",
       "33    nations leading voice childcare advocating aff...\n",
       "34                              penn state alum classof\n",
       "35    mirage homage capri eternal hopeless romantic ...\n",
       "36    lover women dogscats dogs movies comics tv vid...\n",
       "37    collective genre specific blogs combining like...\n",
       "38    militante obrero de los sueos revolucionarios ...\n",
       "39    love animals fetchfind new way find jobs netwo...\n",
       "40                        baby im perfect niallofficial\n",
       "41    kennedy j abulala ni mwalimu anayeienzi kazi y...\n",
       "42                     krothedjgmailcom instagram djkro\n",
       "43                   slightly ginger blue eyes park run\n",
       "44                           living life top food chain\n",
       "45                                            nss ipgkk\n",
       "46                  home office business sweet business\n",
       "47    goodmorning mentions anyone retweeet must foll...\n",
       "48     pc xbox playstation esports music edm stocks sex\n",
       "49    warholian obsessor creating within orwellian n...\n",
       "50                           blades instagram scottryan\n",
       "51         control jpn version zoeojbot rayarkimplosion\n",
       "52    want life advertise service free get rid money...\n",
       "53                                          curious guy\n",
       "54                          discover heal illness pains\n",
       "55    team di reporter e giornalisti lavoriamo con v...\n",
       "56                                           like sleep\n",
       "57            ask questions youll get lies spoopytaylor\n",
       "58    photography bookings enquiries dm call email a...\n",
       "59    born czech republic live ireland wanna germany...\n",
       "60                                          angel could\n",
       "61    following money opening governance fighting co...\n",
       "62                               retired bad girl queen\n",
       "63                                     walk faith sight\n",
       "64    h ncisla bones castle arrow chicago fire chica...\n",
       "65    apollo bot pulling aj dd randomly posts every ...\n",
       "66    south beach th street miami beach fl sunny isl...\n",
       "68    like snow beautiful cold im legal drug dealer ...\n",
       "69    official twitter account wichita falls wildcat...\n",
       "70    wife tidy boy amadeus director ideal place pro...\n",
       "71         delivering uptodate news entertainment world\n",
       "72    lie gets halfway around world truth chance get...\n",
       "73                         lover truth seeker knowledge\n",
       "74    chase trends make statement hoodlyfe httpstcoa...\n",
       "75                      calm collected followbackandsee\n",
       "76    artist reevaluating life radiation oncology st...\n",
       "77    tcg staffing firm places design interactive ma...\n",
       "78    hi name angela friends call angie boring life ...\n",
       "79    sports media opinion established contact us jm...\n",
       "80    repair makes models phones tablets mp players ...\n",
       "81    sportswriter cigar lover dreamer pro writer sp...\n",
       "82                                    charity volunteer\n",
       "83    hip hop usb albums breakstix usb break beats h...\n",
       "85    card get everywhere anything anyhow please use...\n",
       "86                                boring boring chelsea\n",
       "87    dallas tx news need one spot thanks following ...\n",
       "88    maker conceptor creative developer xbacabd con...\n",
       "89                                            calm cool\n",
       "90       retro modernist suffering unsightly visibility\n",
       "91    multiple sclerosis lives brant county together...\n",
       "92    doctorate physics time olympic swimming gold m...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function to convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description'] = data['description'].apply(to_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           sing rhythm\n",
       "1          im author novels filled family drama romance\n",
       "2                               louis whining squealing\n",
       "3     mobile guy ers shazam google kleiner perkins y...\n",
       "4     ricky wilson best frontmankaiser chiefs best b...\n",
       "5                                             dont know\n",
       "6     global marketplace images videos music sharing...\n",
       "7                  secret getting ahead getting started\n",
       "8                           pll fan crazy mcd ramen bae\n",
       "9     renaissance art historian university nottingha...\n",
       "10    clean food tastes great providing energy nutri...\n",
       "11                        highly extraordinary auctions\n",
       "12                                    senior xixiimmxiv\n",
       "13    come join fastest blog network online today ht...\n",
       "14                        im tp bo burnham disney world\n",
       "15                                                 jmkm\n",
       "16    enthusiastic f fan model collector music fan f...\n",
       "17    artisan specializing paper mache printmaking f...\n",
       "18                             bled died take away sins\n",
       "19                                         union j xxxx\n",
       "20                                                start\n",
       "21                          bsc economics graduate coys\n",
       "22          wife coach mom eight troops follower christ\n",
       "23    questions islam would like answer visit httptc...\n",
       "24    canadian space enthusiast future astronaut hop...\n",
       "25                          dms closed sc dearmoonshine\n",
       "26    rlwriter lewd aspiring femboy enjoys oneechans...\n",
       "27    breaking industry news people believe theres t...\n",
       "28    award winning author paranormal romance thrill...\n",
       "29          selfproclaimed princess occasional pain ass\n",
       "30    ksmootyi drink alot could worse im scrolling g...\n",
       "31    everything need find job keep follow tweet new...\n",
       "32            free bros ebk otr real kno grind wea come\n",
       "33    nations leading voice childcare advocating aff...\n",
       "34                              penn state alum classof\n",
       "35    mirage homage capri eternal hopeless romantic ...\n",
       "36    lover women dogscats dogs movies comics tv vid...\n",
       "37    collective genre specific blogs combining like...\n",
       "38    militante obrero de los sueos revolucionarios ...\n",
       "39    love animals fetchfind new way find jobs netwo...\n",
       "40                        baby im perfect niallofficial\n",
       "41    kennedy j abulala ni mwalimu anayeienzi kazi y...\n",
       "42                     krothedjgmailcom instagram djkro\n",
       "43                   slightly ginger blue eyes park run\n",
       "44                           living life top food chain\n",
       "45                                            nss ipgkk\n",
       "46                  home office business sweet business\n",
       "47    goodmorning mentions anyone retweeet must foll...\n",
       "48     pc xbox playstation esports music edm stocks sex\n",
       "49    warholian obsessor creating within orwellian n...\n",
       "50                           blades instagram scottryan\n",
       "51         control jpn version zoeojbot rayarkimplosion\n",
       "52    want life advertise service free get rid money...\n",
       "53                                          curious guy\n",
       "54                          discover heal illness pains\n",
       "55    team di reporter e giornalisti lavoriamo con v...\n",
       "56                                           like sleep\n",
       "57            ask questions youll get lies spoopytaylor\n",
       "58    photography bookings enquiries dm call email a...\n",
       "59    born czech republic live ireland wanna germany...\n",
       "60                                          angel could\n",
       "61    following money opening governance fighting co...\n",
       "62                               retired bad girl queen\n",
       "63                                     walk faith sight\n",
       "64    h ncisla bones castle arrow chicago fire chica...\n",
       "65    apollo bot pulling aj dd randomly posts every ...\n",
       "66    south beach th street miami beach fl sunny isl...\n",
       "68    like snow beautiful cold im legal drug dealer ...\n",
       "69    official twitter account wichita falls wildcat...\n",
       "70    wife tidy boy amadeus director ideal place pro...\n",
       "71         delivering uptodate news entertainment world\n",
       "72    lie gets halfway around world truth chance get...\n",
       "73                         lover truth seeker knowledge\n",
       "74    chase trends make statement hoodlyfe httpstcoa...\n",
       "75                      calm collected followbackandsee\n",
       "76    artist reevaluating life radiation oncology st...\n",
       "77    tcg staffing firm places design interactive ma...\n",
       "78    hi name angela friends call angie boring life ...\n",
       "79    sports media opinion established contact us jm...\n",
       "80    repair makes models phones tablets mp players ...\n",
       "81    sportswriter cigar lover dreamer pro writer sp...\n",
       "82                                    charity volunteer\n",
       "83    hip hop usb albums breakstix usb break beats h...\n",
       "85    card get everywhere anything anyhow please use...\n",
       "86                                boring boring chelsea\n",
       "87    dallas tx news need one spot thanks following ...\n",
       "88    maker conceptor creative developer xbacabd con...\n",
       "89                                            calm cool\n",
       "90       retro modernist suffering unsightly visibility\n",
       "91    multiple sclerosis lives brant county together...\n",
       "92    doctorate physics time olympic swimming gold m...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply function to remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['description'] = data['description'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           sing rhythm\n",
       "1          im author novels filled family drama romance\n",
       "2                               louis whining squealing\n",
       "3     mobile guy ers shazam google kleiner perkins y...\n",
       "4     ricky wilson best frontmankaiser chiefs best b...\n",
       "5                                             dont know\n",
       "6     global marketplace images videos music sharing...\n",
       "7                  secret getting ahead getting started\n",
       "8                           pll fan crazy mcd ramen bae\n",
       "9     renaissance art historian university nottingha...\n",
       "10    clean food tastes great providing energy nutri...\n",
       "11                        highly extraordinary auctions\n",
       "12                                    senior xixiimmxiv\n",
       "13    come join fastest blog network online today ht...\n",
       "14                        im tp bo burnham disney world\n",
       "15                                                 jmkm\n",
       "16    enthusiastic f fan model collector music fan f...\n",
       "17    artisan specializing paper mache printmaking f...\n",
       "18                             bled died take away sins\n",
       "19                                         union j xxxx\n",
       "20                                                start\n",
       "21                          bsc economics graduate coys\n",
       "22          wife coach mom eight troops follower christ\n",
       "23    questions islam would like answer visit httptc...\n",
       "24    canadian space enthusiast future astronaut hop...\n",
       "25                          dms closed sc dearmoonshine\n",
       "26    rlwriter lewd aspiring femboy enjoys oneechans...\n",
       "27    breaking industry news people believe theres t...\n",
       "28    award winning author paranormal romance thrill...\n",
       "29          selfproclaimed princess occasional pain ass\n",
       "30    ksmootyi drink alot could worse im scrolling g...\n",
       "31    everything need find job keep follow tweet new...\n",
       "32            free bros ebk otr real kno grind wea come\n",
       "33    nations leading voice childcare advocating aff...\n",
       "34                              penn state alum classof\n",
       "35    mirage homage capri eternal hopeless romantic ...\n",
       "36    lover women dogscats dogs movies comics tv vid...\n",
       "37    collective genre specific blogs combining like...\n",
       "38    militante obrero de los sueos revolucionarios ...\n",
       "39    love animals fetchfind new way find jobs netwo...\n",
       "40                        baby im perfect niallofficial\n",
       "41    kennedy j abulala ni mwalimu anayeienzi kazi y...\n",
       "42                     krothedjgmailcom instagram djkro\n",
       "43                   slightly ginger blue eyes park run\n",
       "44                           living life top food chain\n",
       "45                                            nss ipgkk\n",
       "46                  home office business sweet business\n",
       "47    goodmorning mentions anyone retweeet must foll...\n",
       "48     pc xbox playstation esports music edm stocks sex\n",
       "49    warholian obsessor creating within orwellian n...\n",
       "50                           blades instagram scottryan\n",
       "51         control jpn version zoeojbot rayarkimplosion\n",
       "52    want life advertise service free get rid money...\n",
       "53                                          curious guy\n",
       "54                          discover heal illness pains\n",
       "55    team di reporter e giornalisti lavoriamo con v...\n",
       "56                                           like sleep\n",
       "57            ask questions youll get lies spoopytaylor\n",
       "58    photography bookings enquiries dm call email a...\n",
       "59    born czech republic live ireland wanna germany...\n",
       "60                                          angel could\n",
       "61    following money opening governance fighting co...\n",
       "62                               retired bad girl queen\n",
       "63                                     walk faith sight\n",
       "64    h ncisla bones castle arrow chicago fire chica...\n",
       "65    apollo bot pulling aj dd randomly posts every ...\n",
       "66    south beach th street miami beach fl sunny isl...\n",
       "68    like snow beautiful cold im legal drug dealer ...\n",
       "69    official twitter account wichita falls wildcat...\n",
       "70    wife tidy boy amadeus director ideal place pro...\n",
       "71         delivering uptodate news entertainment world\n",
       "72    lie gets halfway around world truth chance get...\n",
       "73                         lover truth seeker knowledge\n",
       "74    chase trends make statement hoodlyfe httpstcoa...\n",
       "75                      calm collected followbackandsee\n",
       "76    artist reevaluating life radiation oncology st...\n",
       "77    tcg staffing firm places design interactive ma...\n",
       "78    hi name angela friends call angie boring life ...\n",
       "79    sports media opinion established contact us jm...\n",
       "80    repair makes models phones tablets mp players ...\n",
       "81    sportswriter cigar lover dreamer pro writer sp...\n",
       "82                                    charity volunteer\n",
       "83    hip hop usb albums breakstix usb break beats h...\n",
       "85    card get everywhere anything anyhow please use...\n",
       "86                                boring boring chelsea\n",
       "87    dallas tx news need one spot thanks following ...\n",
       "88    maker conceptor creative developer xbacabd con...\n",
       "89                                            calm cool\n",
       "90       retro modernist suffering unsightly visibility\n",
       "91    multiple sclerosis lives brant county together...\n",
       "92    doctorate physics time olympic swimming gold m...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following function contains the all three tasks for the sake of simplicity we dividied it in three parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the 'description' column\n",
    "data['description'] = data['description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.6: Data After Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Gender Prediction Data After Preprocessing:\n",
      "=================================================\n",
      "\n",
      "   gender                                        description\n",
      "0    male                                        sing rhythm\n",
      "1    male       im author novels filled family drama romance\n",
      "2    male                            louis whining squealing\n",
      "3    male  mobile guy ers shazam google kleiner perkins y...\n",
      "4  female  ricky wilson best frontmankaiser chiefs best b...\n",
      "    gender                                        description\n",
      "88    male  maker conceptor creative developer xbacabd con...\n",
      "89    male                                          calm cool\n",
      "90  female     retro modernist suffering unsightly visibility\n",
      "91   brand  multiple sclerosis lives brant county together...\n",
      "92    male  doctorate physics time olympic swimming gold m...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\\nGender Prediction Data After Preprocessing:\")\n",
    "print(\"=================================================\\n\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have to show tweet first and than to show the sentiment type to make things standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[ 'gender','description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     gender                                        description\n",
      "0      male                                        sing rhythm\n",
      "1      male       im author novels filled family drama romance\n",
      "2      male                            louis whining squealing\n",
      "3      male  mobile guy ers shazam google kleiner perkins y...\n",
      "4    female  ricky wilson best frontmankaiser chiefs best b...\n",
      "5    female                                          dont know\n",
      "6     brand  global marketplace images videos music sharing...\n",
      "7      male               secret getting ahead getting started\n",
      "8    female                        pll fan crazy mcd ramen bae\n",
      "9    female  renaissance art historian university nottingha...\n",
      "10    brand  clean food tastes great providing energy nutri...\n",
      "11    brand                      highly extraordinary auctions\n",
      "12   female                                  senior xixiimmxiv\n",
      "13    brand  come join fastest blog network online today ht...\n",
      "14   female                      im tp bo burnham disney world\n",
      "15   female                                               jmkm\n",
      "16     male  enthusiastic f fan model collector music fan f...\n",
      "17   female  artisan specializing paper mache printmaking f...\n",
      "18   female                           bled died take away sins\n",
      "19   female                                       union j xxxx\n",
      "20     male                                              start\n",
      "21     male                        bsc economics graduate coys\n",
      "22   female        wife coach mom eight troops follower christ\n",
      "23    brand  questions islam would like answer visit httptc...\n",
      "24    brand  canadian space enthusiast future astronaut hop...\n",
      "25   female                        dms closed sc dearmoonshine\n",
      "26     male  rlwriter lewd aspiring femboy enjoys oneechans...\n",
      "27    brand  breaking industry news people believe theres t...\n",
      "28     male  award winning author paranormal romance thrill...\n",
      "29   female        selfproclaimed princess occasional pain ass\n",
      "30     male  ksmootyi drink alot could worse im scrolling g...\n",
      "31    brand  everything need find job keep follow tweet new...\n",
      "32     male          free bros ebk otr real kno grind wea come\n",
      "33    brand  nations leading voice childcare advocating aff...\n",
      "34   female                            penn state alum classof\n",
      "35    brand  mirage homage capri eternal hopeless romantic ...\n",
      "36     male  lover women dogscats dogs movies comics tv vid...\n",
      "37    brand  collective genre specific blogs combining like...\n",
      "38     male  militante obrero de los sueos revolucionarios ...\n",
      "39    brand  love animals fetchfind new way find jobs netwo...\n",
      "40     male                      baby im perfect niallofficial\n",
      "41     male  kennedy j abulala ni mwalimu anayeienzi kazi y...\n",
      "42     male                   krothedjgmailcom instagram djkro\n",
      "43   female                 slightly ginger blue eyes park run\n",
      "44     male                         living life top food chain\n",
      "45   female                                          nss ipgkk\n",
      "46     male                home office business sweet business\n",
      "47   female  goodmorning mentions anyone retweeet must foll...\n",
      "48    brand   pc xbox playstation esports music edm stocks sex\n",
      "49     male  warholian obsessor creating within orwellian n...\n",
      "50     male                         blades instagram scottryan\n",
      "51   female       control jpn version zoeojbot rayarkimplosion\n",
      "52    brand  want life advertise service free get rid money...\n",
      "53     male                                        curious guy\n",
      "54    brand                        discover heal illness pains\n",
      "55    brand  team di reporter e giornalisti lavoriamo con v...\n",
      "56   female                                         like sleep\n",
      "57   female          ask questions youll get lies spoopytaylor\n",
      "58     male  photography bookings enquiries dm call email a...\n",
      "59   female  born czech republic live ireland wanna germany...\n",
      "60     male                                        angel could\n",
      "61     male  following money opening governance fighting co...\n",
      "62   female                             retired bad girl queen\n",
      "63   female                                   walk faith sight\n",
      "64   female  h ncisla bones castle arrow chicago fire chica...\n",
      "65     male  apollo bot pulling aj dd randomly posts every ...\n",
      "66    brand  south beach th street miami beach fl sunny isl...\n",
      "68     male  like snow beautiful cold im legal drug dealer ...\n",
      "69    brand  official twitter account wichita falls wildcat...\n",
      "70   female  wife tidy boy amadeus director ideal place pro...\n",
      "71    brand       delivering uptodate news entertainment world\n",
      "72   female  lie gets halfway around world truth chance get...\n",
      "73     male                       lover truth seeker knowledge\n",
      "74     male  chase trends make statement hoodlyfe httpstcoa...\n",
      "75   female                    calm collected followbackandsee\n",
      "76   female  artist reevaluating life radiation oncology st...\n",
      "77    brand  tcg staffing firm places design interactive ma...\n",
      "78   female  hi name angela friends call angie boring life ...\n",
      "79    brand  sports media opinion established contact us jm...\n",
      "80     male  repair makes models phones tablets mp players ...\n",
      "81     male  sportswriter cigar lover dreamer pro writer sp...\n",
      "82   female                                  charity volunteer\n",
      "83    brand  hip hop usb albums breakstix usb break beats h...\n",
      "85    brand  card get everywhere anything anyhow please use...\n",
      "86  unknown                              boring boring chelsea\n",
      "87    brand  dallas tx news need one spot thanks following ...\n",
      "88     male  maker conceptor creative developer xbacabd con...\n",
      "89     male                                          calm cool\n",
      "90   female     retro modernist suffering unsightly visibility\n",
      "91    brand  multiple sclerosis lives brant county together...\n",
      "92     male  doctorate physics time olympic swimming gold m...\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.7: Saving Cleaned Data as Seperate CSV File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"cleaned_description.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'description'], dtype='object')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Splitting Sample Data into Training Data and Testing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "\n",
    "#### Purpose of Train-Test Split\n",
    "\n",
    "Splitting the dataset into training and testing sets is a crucial step in the machine learning pipeline. It allows us to train our model on one subset of the data and evaluate its performance on another, unseen subset. This helps in assessing the model's ability to generalize to new data.\n",
    "\n",
    "#### Why Split the Data First?\n",
    "\n",
    "Before we can train a machine learning model, we need to split the data into training and testing sets. This ensures that we can evaluate the model's performance on data it hasn't seen during training. Additionally, we need to train the vectorizer (such as TF-IDF) on the training data to convert text to numerical features. Training the vectorizer on the training data ensures that it learns the vocabulary and importance of terms from the training set only, preventing any data leakage from the test set.\n",
    "\n",
    "### TF-IDF Vectorization\n",
    "\n",
    "#### Definition of TF-IDF\n",
    "\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency. It is a statistical measure used to evaluate the importance of a word in a document relative to a collection of documents (corpus). The TF-IDF score increases proportionally to the number of times a word appears in a document but is offset by the frequency of the word in the corpus.\n",
    "\n",
    "- **Term Frequency (TF)**: Measures how frequently a term occurs in a document. \n",
    "  - TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "\n",
    "- **Inverse Document Frequency (IDF)**: Measures how important a term is. \n",
    "  - IDF(t) = log_e(Total number of documents / Number of documents with term t in it)\n",
    "\n",
    "- **TF-IDF**: The product of TF and IDF.\n",
    "  - TF-IDF(t) = TF(t) * IDF(t)\n",
    "\n",
    "#### Reason for Selecting TF-IDF\n",
    "\n",
    "TF-IDF is selected for vectorizing the text data because it not only considers the frequency of words within a document (like Term Frequency) but also adjusts for the fact that some words are generally more common than others (Inverse Document Frequency). This helps in highlighting the more meaningful words in a document and downplaying the less informative ones. \n",
    "\n",
    "Using TF-IDF allows us to convert text data into numerical features that can be used to train machine learning models. This vectorization is essential for applying algorithms that require numerical input.\n",
    "\n",
    "For more details on TF-IDF, you can refer to the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Features and Labels\n",
    "\n",
    "In this step, we separate our data into features (X) and labels (y). The features (X) are the input data that the model will learn from, while the labels (y) are the target values that we want to predict.\n",
    "\n",
    "```python\n",
    "X = data['description']\n",
    "y = data['gender']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 19 72 19\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('cleaned_description.csv')\n",
    "X = data['description']\n",
    "y = data['gender']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Parameters\n",
    "\n",
    "- `train_test_split` is a function from the `sklearn.model_selection` module that splits the data into training and testing sets.\n",
    "- `X_train` and `y_train` are the features and labels for the training set.\n",
    "- `X_test` and `y_test` are the features and labels for the testing set.\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "1. **X and y**:\n",
    "   - `X`: The features or input data, which in this case is the 'tweet' column containing the text data.\n",
    "   - `y`: The labels or target values, which in this case is the 'sentiment_type' column indicating the sentiment of each tweet.\n",
    "\n",
    "2. **test_size**:\n",
    "   - `test_size=0.2` specifies that 20% of the data should be used as the testing set, and the remaining 80% will be used as the training set.\n",
    "   - The `test_size` parameter determines the proportion of the dataset to include in the test split. In this example, 0.2 means that 20% of the data will be allocated to the test set, and 80% will be allocated to the training set.\n",
    "   - Example: If the dataset contains 1000 samples, `test_size=0.2` means 800 samples will be used for training, and 200 samples will be used for testing.\n",
    "\n",
    "3. **random_state**:\n",
    "   - `random_state=42` ensures that the split is reproducible. Using the same `random_state` value will always result in the same split.\n",
    "   - The `random_state` parameter controls the shuffling applied to the data before applying the split. Providing a fixed value (e.g., 42) ensures that you get the same train-test split every time you run the code. This is useful for reproducibility and debugging.\n",
    "   - Example: If you set `random_state=42`, the data will be shuffled in the same way each time you run the code, resulting in the same training and testing sets.\n",
    "\n",
    "By performing this split, we ensure that we have separate datasets for training and evaluating our model, which is crucial for assessing the model's ability to generalize to new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64    h ncisla bones castle arrow chicago fire chica...\n",
       "15                                                 jmkm\n",
       "67    like snow beautiful cold im legal drug dealer ...\n",
       "77    hi name angela friends call angie boring life ...\n",
       "30    ksmootyi drink alot could worse im scrolling g...\n",
       "33    nations leading voice childcare advocating aff...\n",
       "11                        highly extraordinary auctions\n",
       "65    apollo bot pulling aj dd randomly posts every ...\n",
       "68    official twitter account wichita falls wildcat...\n",
       "31    everything need find job keep follow tweet new...\n",
       "76    tcg staffing firm places design interactive ma...\n",
       "9     renaissance art historian university nottingha...\n",
       "69    wife tidy boy amadeus director ideal place pro...\n",
       "5                                             dont know\n",
       "42                     krothedjgmailcom instagram djkro\n",
       "47    goodmorning mentions anyone retweeet must foll...\n",
       "16    enthusiastic f fan model collector music fan f...\n",
       "45                                            nss ipgkk\n",
       "34                              penn state alum classof\n",
       "7                  secret getting ahead getting started\n",
       "79    repair makes models phones tablets mp players ...\n",
       "27    breaking industry news people believe theres t...\n",
       "19                                         union j xxxx\n",
       "75    artist reevaluating life radiation oncology st...\n",
       "25                          dms closed sc dearmoonshine\n",
       "53                                          curious guy\n",
       "13    come join fastest blog network online today ht...\n",
       "24    canadian space enthusiast future astronaut hop...\n",
       "3     mobile guy ers shazam google kleiner perkins y...\n",
       "17    artisan specializing paper mache printmaking f...\n",
       "38    militante obrero de los sueos revolucionarios ...\n",
       "8                           pll fan crazy mcd ramen bae\n",
       "72                         lover truth seeker knowledge\n",
       "6     global marketplace images videos music sharing...\n",
       "87                                            calm cool\n",
       "36    lover women dogscats dogs movies comics tv vid...\n",
       "81                                    charity volunteer\n",
       "56                                           like sleep\n",
       "90    doctorate physics time olympic swimming gold m...\n",
       "54                          discover heal illness pains\n",
       "43                   slightly ginger blue eyes park run\n",
       "50                           blades instagram scottryan\n",
       "46                  home office business sweet business\n",
       "83    card get everywhere anything anyhow please use...\n",
       "61    following money opening governance fighting co...\n",
       "89    multiple sclerosis lives brant county together...\n",
       "73    chase trends make statement hoodlyfe httpstcoa...\n",
       "41    kennedy j abulala ni mwalimu anayeienzi kazi y...\n",
       "58    photography bookings enquiries dm call email a...\n",
       "48     pc xbox playstation esports music edm stocks sex\n",
       "80    sportswriter cigar lover dreamer pro writer sp...\n",
       "57            ask questions youll get lies spoopytaylor\n",
       "32            free bros ebk otr real kno grind wea come\n",
       "86    maker conceptor creative developer xbacabd con...\n",
       "59    born czech republic live ireland wanna germany...\n",
       "63                                     walk faith sight\n",
       "78    sports media opinion established contact us jm...\n",
       "37    collective genre specific blogs combining like...\n",
       "29          selfproclaimed princess occasional pain ass\n",
       "1          im author novels filled family drama romance\n",
       "52    want life advertise service free get rid money...\n",
       "21                          bsc economics graduate coys\n",
       "2                               louis whining squealing\n",
       "23    questions islam would like answer visit httptc...\n",
       "84                                boring boring chelsea\n",
       "74                      calm collected followbackandsee\n",
       "82    hip hop usb albums breakstix usb break beats h...\n",
       "20                                                start\n",
       "60                                          angel could\n",
       "71    lie gets halfway around world truth chance get...\n",
       "14                        im tp bo burnham disney world\n",
       "51         control jpn version zoeojbot rayarkimplosion\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40                        baby im perfect niallofficial\n",
       "22          wife coach mom eight troops follower christ\n",
       "55    team di reporter e giornalisti lavoriamo con v...\n",
       "88       retro modernist suffering unsightly visibility\n",
       "0                                           sing rhythm\n",
       "26    rlwriter lewd aspiring femboy enjoys oneechans...\n",
       "39    love animals fetchfind new way find jobs netwo...\n",
       "66    south beach th street miami beach fl sunny isl...\n",
       "10    clean food tastes great providing energy nutri...\n",
       "44                           living life top food chain\n",
       "85    dallas tx news need one spot thanks following ...\n",
       "35    mirage homage capri eternal hopeless romantic ...\n",
       "70         delivering uptodate news entertainment world\n",
       "62                               retired bad girl queen\n",
       "12                                    senior xixiimmxiv\n",
       "4     ricky wilson best frontmankaiser chiefs best b...\n",
       "18                             bled died take away sins\n",
       "28    award winning author paranormal romance thrill...\n",
       "49    warholian obsessor creating within orwellian n...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: Feature Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization\n",
    "\n",
    "In this step, we use the `TfidfVectorizer` from the `sklearn.feature_extraction.text` module to convert the text data into numerical features based on the TF-IDF (Term Frequency-Inverse Document Frequency) representation. This helps in capturing the importance of words in the context of the documents they appear in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Vectorizer on the Training Data\n",
    "\n",
    "Before we can transform our text data into TF-IDF features, we need to fit the `TfidfVectorizer` on the training data. This step is crucial as it allows the vectorizer to learn the vocabulary and the importance of each term based on the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_features=10)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=10)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the vectorizer on the training data\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the Training Data\n",
    "\n",
    "After fitting the `TfidfVectorizer` on the training data, the next step is to transform the training text data into a TF-IDF feature matrix. This matrix will be used to train our machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training data\n",
    "X_train_tfidf = vectorizer.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the TF-IDF Sparse Matrix to a DataFrame\n",
    "\n",
    "After transforming the text data into a TF-IDF feature matrix, we convert this sparse matrix into a DataFrame. This makes it easier to inspect and manipulate the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Features DataFrame:\n",
      "   art  card  credit  fan  follow  get        im      know      like      want\n",
      "0  0.0   0.0     0.0  0.0     0.0  0.0  0.000000  0.000000  0.000000  0.000000\n",
      "1  0.0   0.0     0.0  0.0     0.0  0.0  0.000000  0.000000  0.000000  0.000000\n",
      "2  0.0   0.0     0.0  0.0     0.0  0.0  0.492371  0.522219  0.492371  0.492371\n",
      "3  0.0   0.0     0.0  0.0     0.0  0.0  0.000000  0.000000  0.000000  0.000000\n",
      "4  0.0   0.0     0.0  0.0     0.0  0.0  1.000000  0.000000  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the TF-IDF sparse matrix to a DataFrame\n",
    "X_train_tfidf_df = pd.DataFrame(X_train_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTF-IDF Features DataFrame:\")\n",
    "print(X_train_tfidf_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming and Converting the Test Data\n",
    "\n",
    "These steps are similar to the ones we performed on the training data, but now we are applying them to the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Features DataFrame:\n",
      "   art  card  credit  fan  follow  get   im  know  like  want\n",
      "0  0.0   0.0     0.0  0.0     0.0  0.0  1.0   0.0   0.0   0.0\n",
      "1  0.0   0.0     0.0  0.0     0.0  0.0  0.0   0.0   0.0   0.0\n",
      "2  0.0   0.0     0.0  0.0     0.0  0.0  0.0   0.0   0.0   0.0\n",
      "3  0.0   0.0     0.0  0.0     0.0  0.0  0.0   0.0   0.0   0.0\n",
      "4  0.0   0.0     0.0  0.0     0.0  0.0  0.0   0.0   0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Transform the training data\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Convert the TF-IDF sparse matrix to a DataFrame\n",
    "X_test_tfidf_df = pd.DataFrame(X_test_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Features DataFrame:\")\n",
    "print(X_test_tfidf_df.head())\n",
    "\n",
    "\n",
    "#to do Parameter tuninng we are not clear how many features are optimal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 : Label Encoding does not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Execute the Training Phase \n",
    "## Step 6.1: Training Data and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.2: Train the model\n",
    "\n",
    "### Training the Model\n",
    "\n",
    "In this step, we train a machine learning model using the TF-IDF features from the training data.\n",
    "\n",
    "`MultinomialNB()`: This initializes a Multinomial Naive Bayes classifier, which is well-suited for classification with discrete features like word counts or TF-IDF scores.\n",
    "`model.fit(X_train_tfidf, y_train)`: This method trains the Multinomial Naive Bayes model using the TF-IDF features (X_train_tfidf) and the corresponding labels (y_train). The model learns the relationship between the features and the labels, which will later be used to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.3: Save the trained model\n",
    "\n",
    "After training the model, it's important to save both the trained model and the TF-IDF vectorizer to disk. This allows us to reuse them later without retraining, which saves time and computational resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to disk\n",
    "joblib.dump(model, 'naive_bayes_model.pkl')\n",
    "\n",
    "# Save the vectorizer to disk\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Execute the Testing Phase \n",
    "## Step 7.1: Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from 'naive_bayes_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "*------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                      |\n",
    "|               Purpose: Method to Load Previously Saved Model  |\n",
    "|         Arguments:                                            |\n",
    "|               Model: Trained Model                            |\n",
    "|         Return:                                               |\n",
    "|               File: Saved Model will be Loaded in Memory      |\n",
    "*---------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Load the model from disk\n",
    "loaded_model = joblib.load('naive_bayes_model.pkl')\n",
    "\n",
    "# Load the vectorizer from disk\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "print(f\"Model loaded from 'naive_bayes_model.pkl'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.2: Evaluate the Machine Learning Model\n",
    "\n",
    "### Transforming Test Data and Evaluating the Loaded Model\n",
    "\n",
    "Transform the test data using the loaded vectorizer: This step uses the loaded TF-IDF vectorizer to transform the test data (`X_test`) into the same TF-IDF feature matrix format as used during training.\n",
    "\n",
    "`X_test_tfidf_loaded = loaded_vectorizer.transform(X_test)`: This transforms the test text data into a TF-IDF feature matrix using the loaded vectorizer.\n",
    "\n",
    "Evaluate the loaded model: This step uses the loaded model to make predictions on the transformed test data and then evaluates the model's performance.\n",
    "\n",
    "`y_pred_loaded = loaded_model.predict(X_test_tfidf_loaded)`: This uses the loaded model to predict the labels for the transformed test data.\n",
    "`accuracy_loaded = accuracy_score(y_test, y_pred_loaded)`: This calculates the accuracy of the model's predictions by comparing the predicted labels (`y_pred_loaded`) with the true labels (`y_test`).\n",
    "`report_loaded = classification_report(y_test, y_pred_loaded)`: This generates a detailed classification report, which includes precision, recall, and F1-score for each class.\n",
    "\n",
    "Print the results: This step prints the accuracy and the classification report to provide a summary of the model's performance on the test data.\n",
    "\n",
    "`print(f\"Accuracy: {accuracy_loaded}\")`: This prints the accuracy of the model.\n",
    "`print(\"Classification Report:\")`: This prints a header for the classification report.\n",
    "`print(report_loaded)`: This prints the detailed classification report, providing insights into the model's performance across different classes.\n",
    "\n",
    "By transforming the test data and evaluating the loaded model, we can assess the model's ability to generalize to new, unseen data and ensure that it performs as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3157894736842105\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       brand       0.00      0.00      0.00         7\n",
      "      female       0.00      0.00      0.00         6\n",
      "        male       0.32      1.00      0.48         6\n",
      "\n",
      "    accuracy                           0.32        19\n",
      "   macro avg       0.11      0.33      0.16        19\n",
      "weighted avg       0.10      0.32      0.15        19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Transform the test data using the loaded vectorizer\n",
    "X_test_tfidf_loaded = loaded_vectorizer.transform(X_test)\n",
    "\n",
    "# Evaluate the loaded model\n",
    "y_pred_loaded = loaded_model.predict(X_test_tfidf_loaded)\n",
    "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
    "report_loaded = classification_report(y_test, y_pred_loaded)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_loaded}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report_loaded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Execute the Application Phase\n",
    "## Step 8.1: Take Input from User, Preprocess it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take user input\n",
    "user_input = input(\"Please enter your text: \").strip()\n",
    "\n",
    "# Preprocess the user input\n",
    "def preprocess_user_input(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "cleaned_input = preprocess_user_input(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love art and I ama huge fan of van doe'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input\n",
    "# If they are successful, we can rest assured that the COVID-19 best vaccine will not irritate our eyes this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love art ama huge fan van doe'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.2: Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vectorizer and the model (ensure these are the same as used during training)\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "model = joblib.load('naive_bayes_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.3: Transform the user input using the loaded vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Features DataFrame for User Input:\n",
      "        art  card  credit      fan  follow  get   im  know  like  want\n",
      "0  0.731771   0.0     0.0  0.68155     0.0  0.0  0.0   0.0   0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Transform the cleaned input using the vectorizer\n",
    "X_test_tfidf = vectorizer.transform([cleaned_input])  # Wrap the cleaned input in a list\n",
    "\n",
    "# Convert the TF-IDF sparse matrix to a DataFrame\n",
    "X_test_tfidf_df = pd.DataFrame(X_test_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTF-IDF Features DataFrame for User Input:\")\n",
    "print(X_test_tfidf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the user input using the loaded vectorizer\n",
    "user_input_tfidf = vectorizer.transform([cleaned_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.4: Predict the Gender of the user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gender of  user is: female evaluated from their input: I love art and I ama huge fan of van doe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MultinomialNB was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predict the sentiment of the user input\n",
    "user_prediction = model.predict(X_test_tfidf_df)#\n",
    "\n",
    "\n",
    "#Output\n",
    "print(f\"The gender of  user is: {user_prediction[0]} evaluated from their input: {user_input}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Execute the Feedback Phase\n",
    "## A Two-Step Process\n",
    "### Step 01: After some time, take Feedback from\n",
    "    o\tDomain Experts and Users on deployed Titanic Passenger Survival Prediction System\n",
    "### Step 02: Make a List of Possible Improvements based on Feedback received"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo gender identificaton form text\n",
    "\n",
    "muti clas age group identification from text, emotion redectipn fronm text. mahy by personalityh type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Improve Model based on Feedback\n",
    "### There is Always Room for Improvement\n",
    "### Based on Feedback from Domain Experts and Users\n",
    "    o\tImprove your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo Task\n",
    "\n",
    "## Choose a dataset from the following links and repeat the processes mentioned in this notebook:\n",
    "The first dataset is compulsory, while the others are provided for additional practice.\n",
    "\n",
    "1. **[Spam Email Dataset](https://www.kaggle.com/datasets/jackksoncsie/spam-email-dataset)** (Compulsory)\n",
    "2. [COVID-19 NLP Text Classification](https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification) (For practice)\n",
    "3. [Fake News Detection](https://www.kaggle.com/datasets/vishakhdapat/fake-news-detection) (For practice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
    "<center> <h3 style=\"color:green\">JAZAK ALLAH KHAIR</h3> \n",
    "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
    "<br><br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
